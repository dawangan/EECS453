{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cuda\n",
      "[INFO] Test dir: c:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\test_data_tiff\n",
      "[OK] Loaded: c:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\best_unet.pth\n",
      "  missing keys (sample): ['inc.net.0.gn.weight', 'inc.net.0.gn.bias', 'inc.net.1.gn.weight', 'inc.net.1.gn.bias', 'down1.1.net.0.gn.weight', 'down1.1.net.0.gn.bias', 'down1.1.net.1.gn.weight', 'down1.1.net.1.gn.bias'] ...\n",
      "  unexpected keys (sample): ['inc.net.0.norm.weight', 'inc.net.0.norm.bias', 'inc.net.1.norm.weight', 'inc.net.1.norm.bias', 'down1.1.net.0.norm.weight', 'down1.1.net.0.norm.bias', 'down1.1.net.1.norm.weight', 'down1.1.net.1.norm.bias'] ...\n",
      "[OK] Loaded: c:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\best_resattn_unet_ds.pth\n",
      "  missing keys (sample): ['stem.conv1.weight', 'stem.gn1.weight', 'stem.gn1.bias', 'stem.conv2.weight', 'stem.gn2.weight', 'stem.gn2.bias', 'd1.1.conv1.weight', 'd1.1.gn1.weight'] ...\n",
      "  unexpected keys (sample): ['bott.c1.conv.weight', 'bott.c1.norm.weight', 'bott.c1.norm.bias', 'bott.c2.weight', 'bott.g2.weight', 'bott.g2.bias', 'head1.weight', 'head1.bias'] ...\n",
      "\n",
      "[RUN] Full-image inference: raw_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vonkl\\AppData\\Local\\Temp\\ipykernel_28520\\2686394021.py:309: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] c:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\inference_outputs_fulltest\\raw_13_COMPARISON_PANEL.png\n",
      "\n",
      "[RUN] Full-image inference: raw_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vonkl\\AppData\\Local\\Temp\\ipykernel_28520\\2686394021.py:309: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] c:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\inference_outputs_fulltest\\raw_14_COMPARISON_PANEL.png\n",
      "\n",
      "[DONE] Outputs in: c:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\inference_outputs_fulltest\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "CLASS_NAMES = [\"Background\", \"Yellow\", \"Green\", \"Red\", \"Blue\"]\n",
    "\n",
    "REPO_ROOT = os.getcwd()\n",
    "\n",
    "TEST_DIR = os.path.join(REPO_ROOT, \"project\", \"test_data_tiff\")\n",
    "\n",
    "CKPT_UNET = os.path.join(REPO_ROOT, \"best_unet.pth\")\n",
    "CKPT_RES  = os.path.join(REPO_ROOT, \"best_resattn_unet_ds.pth\")\n",
    "\n",
    "OUT_DIR = os.path.join(REPO_ROOT, \"project\", \"inference_outputs_fulltest\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE_AUTOMIX = True   \n",
    "TILE = 512\n",
    "STRIDE = 400  \n",
    "def robust_normalize(img: np.ndarray) -> np.ndarray:\n",
    "    img = img.astype(np.float32)\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    if (p98 - p2) < 1e-6:\n",
    "        return np.zeros_like(img, dtype=np.float32)\n",
    "    img = (img - p2) / (p98 - p2)\n",
    "    return np.clip(img, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def ensure_2d(img: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    if img.ndim == 3:\n",
    "        img = img[..., 0]\n",
    "    return img\n",
    "\n",
    "def pad_to_tile(img: np.ndarray, tile=TILE) -> tuple[np.ndarray, tuple[int,int]]:\n",
    "    h, w = img.shape\n",
    "    pad_h = (tile - (h % tile)) % tile\n",
    "    pad_w = (tile - (w % tile)) % tile\n",
    "    if pad_h or pad_w:\n",
    "        img = np.pad(img, ((0, pad_h), (0, pad_w)), mode=\"reflect\")\n",
    "    return img, (pad_h, pad_w)\n",
    "\n",
    "def unpad(img: np.ndarray, pad_hw: tuple[int,int]) -> np.ndarray:\n",
    "    pad_h, pad_w = pad_hw\n",
    "    if pad_h:\n",
    "        img = img[:-pad_h, :]\n",
    "    if pad_w:\n",
    "        img = img[:, :-pad_w]\n",
    "    return img\n",
    "\n",
    "def discrete_cmap():\n",
    " \n",
    "    return plt.colormaps[\"tab10\"].resampled(NUM_CLASSES)\n",
    "\n",
    "def gn(ch): return nn.GroupNorm(8, ch)\n",
    "\n",
    "class ConvGNAct(nn.Module):\n",
    "    \"\"\"Single conv + GN + ReLU. Used to build a DoubleConv style block by stacking.\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, padding=p, bias=False)\n",
    "        self.gn = gn(out_ch)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        return self.act(self.gn(self.conv(x)))\n",
    "\n",
    "class DoubleConvGN(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ConvGNAct(in_ch, out_ch),\n",
    "            ConvGNAct(out_ch, out_ch),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Matches your described UNet:\n",
    "    inc -> down1 -> down2 -> down3 -> up1+skip(x3) -> up2+skip(x2) -> up3+skip(x1) -> out\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=5, base=64):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConvGN(1, base)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN(base, base*2))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN(base*2, base*4))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN(base*4, base*8))\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
    "        self.conv1 = DoubleConvGN(base*8, base*4)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
    "        self.conv2 = DoubleConvGN(base*4, base*2)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
    "        self.conv3 = DoubleConvGN(base*2, base)\n",
    "\n",
    "        self.outc = nn.Conv2d(base, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)    \n",
    "        x2 = self.down1(x1) \n",
    "        x3 = self.down2(x2) \n",
    "        x4 = self.down3(x3) \n",
    "\n",
    "        x = self.up1(x4)\n",
    "        x = self.conv1(torch.cat([x3, x], dim=1))\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = self.conv2(torch.cat([x2, x], dim=1))\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = self.conv3(torch.cat([x1, x], dim=1))\n",
    "\n",
    "        return self.outc(x)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.gn1 = gn(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.gn2 = gn(out_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.gn1(self.conv1(x)))\n",
    "        h = self.gn2(self.conv2(h))\n",
    "        return self.act(h + self.skip(x))\n",
    "\n",
    "import os, re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _clean_state_dict(state):\n",
    "\n",
    "    if isinstance(state, dict) and (\"state_dict\" in state):\n",
    "        state = state[\"state_dict\"]\n",
    "    if isinstance(state, dict) and (\"model\" in state):\n",
    "        state = state[\"model\"]\n",
    "\n",
    "    if isinstance(state, dict):\n",
    "        new = {}\n",
    "        for k, v in state.items():\n",
    "            nk = k\n",
    "            if nk.startswith(\"module.\"):\n",
    "                nk = nk[len(\"module.\"):]\n",
    "            new[nk] = v\n",
    "        return new\n",
    "    return state\n",
    "\n",
    "def load_weights_strict(model, ckpt_path, device=\"cpu\"):\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    state = torch.load(ckpt_path, map_location=device)\n",
    "    state = _clean_state_dict(state)\n",
    "    missing, unexpected = model.load_state_dict(state, strict=True)\n",
    "    print(f\"[OK] Loaded: {ckpt_path}\")\n",
    "    return missing, unexpected\n",
    "\n",
    "def gn(ch): return nn.GroupNorm(8, ch)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.gn1 = gn(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.gn2 = gn(out_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.gn1(self.conv1(x)))\n",
    "        h = self.gn2(self.conv2(h))\n",
    "        return self.act(h + self.skip(x))\n",
    "\n",
    "class AttnGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention gate with reduced intermediate channels:\n",
    "      theta: skip_ch -> inter_ch\n",
    "      phi:   gate_ch -> inter_ch\n",
    "      psi:   inter_ch -> 1\n",
    "    This matches your checkpoint shapes like [24,48,1,1], [1,24,1,1], etc.\n",
    "    \"\"\"\n",
    "    def __init__(self, skip_ch, gate_ch, inter_ch=None):\n",
    "        super().__init__()\n",
    "        if inter_ch is None:\n",
    "            inter_ch = max(1, skip_ch // 2)\n",
    "\n",
    "        self.theta = nn.Conv2d(skip_ch, inter_ch, 1, bias=False)\n",
    "        self.phi   = nn.Conv2d(gate_ch, inter_ch, 1, bias=False)\n",
    "        self.psi   = nn.Conv2d(inter_ch, 1, 1, bias=True)\n",
    "        self.act   = nn.SiLU(inplace=True)\n",
    "        self.sig   = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, skip, gate):\n",
    "        g = F.interpolate(gate, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        a = self.act(self.theta(skip) + self.phi(g))\n",
    "        a = self.sig(self.psi(a))\n",
    "        return skip * a\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.reduce = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "       \n",
    "        self.attn = AttnGate(skip_ch=out_ch, gate_ch=out_ch, inter_ch=max(1, out_ch // 2))\n",
    "        self.block = ResBlock(out_ch * 2, out_ch)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = self.reduce(x)\n",
    "        s = self.attn(skip, x)\n",
    "        return self.block(torch.cat([s, x], dim=1))\n",
    "\n",
    "class ResAttnUNetDS(nn.Module):\n",
    "    def __init__(self, n_classes=5, base=48):\n",
    "        super().__init__()\n",
    "        self.stem   = ResBlock(1, base)\n",
    "        self.d1     = nn.Sequential(nn.MaxPool2d(2), ResBlock(base, base*2))\n",
    "        self.d2     = nn.Sequential(nn.MaxPool2d(2), ResBlock(base*2, base*4))\n",
    "        self.d3     = nn.Sequential(nn.MaxPool2d(2), ResBlock(base*4, base*8))\n",
    "        self.d4     = nn.Sequential(nn.MaxPool2d(2), ResBlock(base*8, base*12))\n",
    "        self.bottle = ResBlock(base*12, base*12)\n",
    "\n",
    "        self.u3 = UpBlock(base*12, base*8)\n",
    "        self.u2 = UpBlock(base*8,  base*4)\n",
    "        self.u1 = UpBlock(base*4,  base*2)\n",
    "        self.u0 = UpBlock(base*2,  base)\n",
    "\n",
    "        self.head0 = nn.Conv2d(base, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem(x)\n",
    "        s1 = self.d1(s0)\n",
    "        s2 = self.d2(s1)\n",
    "        s3 = self.d3(s2)\n",
    "        s4 = self.d4(s3)\n",
    "        b  = self.bottle(s4)\n",
    "\n",
    "        x = self.u3(b,  s3)\n",
    "        x = self.u2(x,  s2)\n",
    "        x = self.u1(x,  s1)\n",
    "        x = self.u0(x,  s0)\n",
    "        return self.head0(x)\n",
    "\n",
    "\n",
    "def load_weights_strict(model, ckpt_path):\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    state = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "    print(f\"[OK] Loaded: {ckpt_path}\")\n",
    "    if missing:\n",
    "        print(\"  missing keys (sample):\", missing[:8], (\"...\" if len(missing)>8 else \"\"))\n",
    "    if unexpected:\n",
    "        print(\"  unexpected keys (sample):\", unexpected[:8], (\"...\" if len(unexpected)>8 else \"\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_full_image_logits(model, img01: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    img01: normalized float32 in [0,1], shape HxW\n",
    "    returns:\n",
    "      pred: HxW uint8 argmax\n",
    "      entropy: HxW float32 entropy map\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    img_pad, pad_hw = pad_to_tile(img01, tile=TILE)\n",
    "    H, W = img_pad.shape\n",
    "\n",
    "    num = np.zeros((NUM_CLASSES, H, W), dtype=np.float32)\n",
    "    den = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    wy = np.hanning(TILE).astype(np.float32)\n",
    "    wx = np.hanning(TILE).astype(np.float32)\n",
    "    w2 = (wy[:, None] * wx[None, :])\n",
    "    w2 = np.maximum(w2, 1e-3)  \n",
    "\n",
    "    autocast_on = (DEVICE.startswith(\"cuda\") and DTYPE_AUTOMIX)\n",
    "\n",
    "    for y in range(0, H - TILE + 1, STRIDE):\n",
    "        for x in range(0, W - TILE + 1, STRIDE):\n",
    "            patch = img_pad[y:y+TILE, x:x+TILE]\n",
    "            t = torch.from_numpy(patch).unsqueeze(0).unsqueeze(0).to(DEVICE)  \n",
    "\n",
    "            if autocast_on:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(t) \n",
    "            else:\n",
    "                logits = model(t)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)[0].float().cpu().numpy()  \n",
    "\n",
    "            num[:, y:y+TILE, x:x+TILE] += probs * w2[None, :, :]\n",
    "            den[y:y+TILE, x:x+TILE] += w2\n",
    "\n",
    "    probs_full = num / (den[None, :, :] + 1e-8) \n",
    "    probs_full = probs_full.astype(np.float32)\n",
    "\n",
    "    ent = -np.sum(probs_full * np.log(probs_full + 1e-8), axis=0).astype(np.float32)\n",
    "\n",
    "    pred = np.argmax(probs_full, axis=0).astype(np.uint8)\n",
    "\n",
    "    pred = unpad(pred, pad_hw)\n",
    "    ent  = unpad(ent,  pad_hw)\n",
    "    return pred, ent\n",
    "\n",
    "def save_full_outputs(base_name, img01, pred_unet, ent_unet, pred_res, ent_res):\n",
    "    cmap = discrete_cmap()\n",
    "\n",
    "    for tag, pred in [(\"unet\", pred_unet), (\"resattn\", pred_res)]:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        im = plt.imshow(pred, vmin=0, vmax=NUM_CLASSES-1, cmap=cmap)\n",
    "        plt.title(f\"{base_name} — {tag.upper()} prediction (full image)\")\n",
    "        cbar = plt.colorbar(im, fraction=0.03, pad=0.02, ticks=list(range(NUM_CLASSES)))\n",
    "        cbar.ax.set_yticklabels(CLASS_NAMES)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{base_name}_{tag}_full_pred.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    for tag, ent in [(\"unet\", ent_unet), (\"resattn\", ent_res)]:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(ent, cmap=\"magma\")\n",
    "        plt.title(f\"{base_name} — {tag.upper()} entropy (uncertainty)\")\n",
    "        plt.colorbar(fraction=0.03, pad=0.02)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"{base_name}_{tag}_entropy.png\"), dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(22, 5))\n",
    "    ax[0].imshow(img01, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Input (normalized)\")\n",
    "\n",
    "    ax[1].imshow(pred_unet, vmin=0, vmax=NUM_CLASSES-1, cmap=cmap)\n",
    "    ax[1].set_title(\"UNet: argmax class\")\n",
    "\n",
    "    ax[2].imshow(ent_unet, cmap=\"magma\")\n",
    "    ax[2].set_title(\"UNet: entropy\")\n",
    "\n",
    "    ax[3].imshow(pred_res, vmin=0, vmax=NUM_CLASSES-1, cmap=cmap)\n",
    "    ax[3].set_title(\"ResAttn: argmax class\")\n",
    "\n",
    "    ax[4].imshow(ent_res, cmap=\"magma\")\n",
    "    ax[4].set_title(\"ResAttn: entropy\")\n",
    "\n",
    "    for a in ax:\n",
    "        a.axis(\"off\")\n",
    "\n",
    "\n",
    "    caption = (\n",
    "        \"Full-image stitched predictions from 512×512 patches (stride 400). \"\n",
    "        \"Argmax maps show predicted class per pixel; entropy highlights uncertainty (higher=less confident). \"\n",
    "        \"Colors correspond to the 5 classes shown in the legend/colorbar in the individual prediction figures.\"\n",
    "    )\n",
    "    fig.text(0.5, -0.02, caption, ha=\"center\", va=\"top\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(OUT_DIR, f\"{base_name}_COMPARISON_PANEL.png\")\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(\"[SAVED]\", out_path)\n",
    "\n",
    "def main():\n",
    "    print(\"[INFO] Device:\", DEVICE)\n",
    "    print(\"[INFO] Test dir:\", TEST_DIR)\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    test_raws = sorted(glob.glob(os.path.join(TEST_DIR, \"*.tif*\"))) + sorted(glob.glob(os.path.join(TEST_DIR, \"*.tiff\")))\n",
    "    test_raws = sorted(list(set(test_raws)))\n",
    "    if not test_raws:\n",
    "        raise RuntimeError(f\"No TIFF files found in {TEST_DIR}\")\n",
    "\n",
    "    unet = SimpleUNet(n_classes=NUM_CLASSES, base=64).to(DEVICE)\n",
    "    res  = ResAttnUNetDS(n_classes=NUM_CLASSES, base=48).to(DEVICE)\n",
    "\n",
    "    load_weights_strict(unet, CKPT_UNET)\n",
    "    load_weights_strict(res,  CKPT_RES)\n",
    "\n",
    "    for raw_p in test_raws:\n",
    "        base = os.path.splitext(os.path.basename(raw_p))[0]\n",
    "        print(\"\\n[RUN] Full-image inference:\", base)\n",
    "\n",
    "        img = np.array(Image.open(raw_p))\n",
    "        img = ensure_2d(img)\n",
    "        img01 = robust_normalize(img)\n",
    "\n",
    "        pred_u, ent_u = predict_full_image_logits(unet, img01)\n",
    "        pred_r, ent_r = predict_full_image_logits(res,  img01)\n",
    "\n",
    "        save_full_outputs(base, img01, pred_u, ent_u, pred_r, ent_r)\n",
    "\n",
    "    print(\"\\n[DONE] Outputs in:\", OUT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9158b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

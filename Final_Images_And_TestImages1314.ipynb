{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a4f4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UNet: project/best_unet_godmode_v2.pth\n",
      "Loading ResNet: best_resattn_unet_ds.pth\n",
      "\n",
      "Processing 2 images...\n",
      "\n",
      "Target: raw_13\n",
      "  > Processing 210 tiles (TTA=True)...\n",
      "  ✅ Saved fixed output.\n",
      "\n",
      "Target: raw_14\n",
      "  > Processing 20 tiles (TTA=True)...\n",
      "  ✅ Saved fixed output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & TUNING\n",
    "# ==========================================\n",
    "PATH_UNET   = \"project/best_unet_godmode_v2.pth\"  # The \"Detailed\" model\n",
    "PATH_RESNET = \"best_resattn_unet_ds.pth\"          # The \"High Score\" model\n",
    "\n",
    "TEST_DATA_DIR = r\"C:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\test_data_tiff\"\n",
    "OUTPUT_DIR    = os.path.join(TEST_DATA_DIR, \"outputs_fixed\")\n",
    "\n",
    "# --- TUNING KNOBS (The Fix) ---\n",
    "# 1. Background Suppression: Lower value = More Details (Range: 0.1 to 1.0)\n",
    "#    - 1.0 = Default (Conservative)\n",
    "#    - 0.5 = Aggressive (Forces model to predict classes even if uncertain)\n",
    "RESNET_BG_SCALE = 0.4  \n",
    "\n",
    "# 2. Ensemble Weights: How much to trust each model?\n",
    "#    - Trust ResNet for structure (0.6), UNet for detail (0.4)\n",
    "WEIGHT_RESNET = 0.6\n",
    "WEIGHT_UNET   = 0.4\n",
    "\n",
    "# 3. TTA (Test Time Augmentation): Averages original + flipped images\n",
    "#    - Increases runtime but significantly improves detail/smoothness\n",
    "USE_TTA = True\n",
    "\n",
    "# Standard Config\n",
    "NUM_CLASSES = 5\n",
    "TILE_SIZE   = 512\n",
    "STRIDE      = 400\n",
    "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. PRE-PROCESSING\n",
    "# ==========================================\n",
    "def robust_normalize(img):\n",
    "    img = img.astype(np.float32)\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    if p98 - p2 < 1e-6: return np.zeros_like(img, dtype=np.float32)\n",
    "    img = (img - p2) / (p98 - p2)\n",
    "    return np.clip(img, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def calculate_entropy(probs):\n",
    "    epsilon = 1e-6\n",
    "    entropy = -torch.sum(probs * torch.log(probs + epsilon), dim=0)\n",
    "    return entropy\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL ARCHITECTURES\n",
    "# ==========================================\n",
    "# --- UNet ---\n",
    "class DoubleConvGN_Start2(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConvGN_Start2(1, 64)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN_Start2(64, 128))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN_Start2(128, 256))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN_Start2(256, 512))\n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, 2, 2); self.conv1 = DoubleConvGN_Start2(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2); self.conv2 = DoubleConvGN_Start2(256, 128)\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, 2, 2); self.conv3 = DoubleConvGN_Start2(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1); x3 = self.down2(x2); x4 = self.down3(x3)\n",
    "        x = self.up1(x4); x = torch.cat([x3, x], dim=1); x = self.conv1(x)\n",
    "        x = self.up2(x); x = torch.cat([x2, x], dim=1); x = self.conv2(x)\n",
    "        x = self.up3(x); x = torch.cat([x1, x], dim=1); x = self.conv3(x)\n",
    "        return self.outc(x)\n",
    "\n",
    "# --- ResAttnUNet ---\n",
    "def gn_resu(ch, groups=8):\n",
    "    groups = min(groups, ch)\n",
    "    while groups > 1 and (ch % groups != 0): groups -= 1\n",
    "    return nn.GroupNorm(groups, ch)\n",
    "\n",
    "class ConvGNAct_Resu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, padding=p, bias=False)\n",
    "        self.gn = gn_resu(out_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "    def forward(self, x): return self.act(self.gn(self.conv(x)))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.c1 = ConvGNAct_Resu(in_ch, out_ch)\n",
    "        self.c2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.g2 = gn_resu(out_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        h = self.c1(x); h = self.g2(self.c2(h))\n",
    "        return self.act(h + self.skip(x))\n",
    "\n",
    "class AttnGate(nn.Module):\n",
    "    def __init__(self, skip_ch, gate_ch, inter_ch):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Conv2d(skip_ch, inter_ch, 1, bias=False); self.phi = nn.Conv2d(gate_ch, inter_ch, 1, bias=False)\n",
    "        self.psi = nn.Conv2d(inter_ch, 1, 1, bias=True); self.act = nn.SiLU(inplace=True); self.sig = nn.Sigmoid()\n",
    "    def forward(self, skip, gate):\n",
    "        g = F.interpolate(gate, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        a = self.act(self.theta(skip) + self.phi(g))\n",
    "        return skip * self.sig(self.psi(a))\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__(); self.pool = nn.MaxPool2d(2); self.block = ResBlock(in_ch, out_ch)\n",
    "    def forward(self, x): return self.block(self.pool(x))\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.reduce = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        self.attn = AttnGate(skip_ch, out_ch, inter_ch=max(16, out_ch // 2))\n",
    "        self.block = ResBlock(out_ch + skip_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x); x = self.reduce(x); skip = self.attn(skip, x)\n",
    "        return self.block(torch.cat([skip, x], dim=1))\n",
    "\n",
    "class ResAttnUNetDS(nn.Module):\n",
    "    def __init__(self, n_classes=5, base=48):\n",
    "        super().__init__()\n",
    "        c1, c2, c3, c4, c5 = base, base*2, base*4, base*8, base*12\n",
    "        self.stem = ResBlock(1, c1)\n",
    "        self.d1 = Down(c1, c2); self.d2 = Down(c2, c3); self.d3 = Down(c3, c4); self.d4 = Down(c4, c5)\n",
    "        self.bottleneck = ResBlock(c5, c5)\n",
    "        self.u3 = Up(c5, c4, c4); self.u2 = Up(c4, c3, c3); self.u1 = Up(c3, c2, c2); self.u0 = Up(c2, c1, c1)\n",
    "        self.head0 = nn.Conv2d(c1, n_classes, 1)\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem(x); s1 = self.d1(s0); s2 = self.d2(s1); s3 = self.d3(s2); s4 = self.d4(s3)\n",
    "        b = self.bottleneck(s4)\n",
    "        x3 = self.u3(b, s3); x2 = self.u2(x3, s2); x1 = self.u1(x2, s1); x0 = self.u0(x1, s0)\n",
    "        return self.head0(x0)\n",
    "\n",
    "# ==========================================\n",
    "# 4. ADVANCED INFERENCE (TTA + Sliding Window)\n",
    "# ==========================================\n",
    "def get_model_probs(model, tile_tensor, use_tta=False):\n",
    "    \"\"\"Returns softmax probabilities, optionally using TTA (HFlip/VFlip)\"\"\"\n",
    "    # 1. Standard\n",
    "    logits = model(tile_tensor)\n",
    "    if isinstance(logits, tuple): logits = logits[0]\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    \n",
    "    if use_tta:\n",
    "        # 2. Horizontal Flip\n",
    "        logits_hf = model(torch.flip(tile_tensor, [3]))\n",
    "        if isinstance(logits_hf, tuple): logits_hf = logits_hf[0]\n",
    "        probs_hf = torch.softmax(logits_hf, dim=1)\n",
    "        probs += torch.flip(probs_hf, [3])\n",
    "        \n",
    "        # 3. Vertical Flip\n",
    "        logits_vf = model(torch.flip(tile_tensor, [2]))\n",
    "        if isinstance(logits_vf, tuple): logits_vf = logits_vf[0]\n",
    "        probs_vf = torch.softmax(logits_vf, dim=1)\n",
    "        probs += torch.flip(probs_vf, [2])\n",
    "        \n",
    "        probs /= 3.0 # Average\n",
    "        \n",
    "    return probs\n",
    "\n",
    "def run_inference(models, img_array):\n",
    "    \"\"\"\n",
    "    Runs sliding window inference with Ensemble + TTA + Sensitivity Adjustment\n",
    "    \"\"\"\n",
    "    h, w = img_array.shape\n",
    "    # Accumulators for the ENSEMBLE\n",
    "    ens_prob_sum = torch.zeros((NUM_CLASSES, h, w), dtype=torch.float32, device=DEVICE)\n",
    "    count_map = torch.zeros((1, h, w), dtype=torch.float32, device=DEVICE)\n",
    "    \n",
    "    y_starts = sorted(list(set(list(range(0, h, STRIDE)) + [max(0, h - TILE_SIZE)])))\n",
    "    x_starts = sorted(list(set(list(range(0, w, STRIDE)) + [max(0, w - TILE_SIZE)])))\n",
    "    \n",
    "    print(f\"  > Processing {len(y_starts)*len(x_starts)} tiles (TTA={USE_TTA})...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for y in y_starts:\n",
    "            for x in x_starts:\n",
    "                y_end, x_end = min(y + TILE_SIZE, h), min(x + TILE_SIZE, w)\n",
    "                tile = img_array[y:y_end, x:x_end]\n",
    "                th, tw = tile.shape\n",
    "                \n",
    "                # Reflect Pad\n",
    "                pad_h, pad_w = TILE_SIZE - th, TILE_SIZE - tw\n",
    "                if pad_h > 0 or pad_w > 0:\n",
    "                    tile = np.pad(tile, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
    "                \n",
    "                inp = torch.from_numpy(tile).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "                \n",
    "                # --- A. UNet Prediction ---\n",
    "                probs_unet = get_model_probs(models['UNet'], inp, use_tta=USE_TTA)\n",
    "                \n",
    "                # --- B. ResNet Prediction (With Sensitivity Fix) ---\n",
    "                probs_res = get_model_probs(models['ResNet'], inp, use_tta=USE_TTA)\n",
    "                \n",
    "                # FIX: Suppress ResNet Background\n",
    "                # We multiply Class 0 prob by RESNET_BG_SCALE (e.g., 0.5)\n",
    "                # Then re-normalize so they sum to 1.0\n",
    "                probs_res[:, 0, :, :] *= RESNET_BG_SCALE\n",
    "                probs_res = probs_res / probs_res.sum(dim=1, keepdim=True)\n",
    "                \n",
    "                # --- C. Weighted Ensemble ---\n",
    "                # Combine: (0.4 * UNet) + (0.6 * Fixed_ResNet)\n",
    "                probs_tile = (probs_unet * WEIGHT_UNET) + (probs_res * WEIGHT_RESNET)\n",
    "                \n",
    "                # Crop and Accumulate\n",
    "                probs_tile = probs_tile[0, :, :th, :tw]\n",
    "                ens_prob_sum[:, y:y_end, x:x_end] += probs_tile\n",
    "                count_map[:, y:y_end, x:x_end] += 1.0\n",
    "\n",
    "    avg_probs = ens_prob_sum / count_map\n",
    "    pred_map = torch.argmax(avg_probs, dim=0).cpu().numpy().astype(np.uint8)\n",
    "    ent_map = calculate_entropy(avg_probs).cpu().numpy()\n",
    "    \n",
    "    return pred_map, ent_map\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN\n",
    "# ==========================================\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    models = {}\n",
    "\n",
    "    # Load Models\n",
    "    print(f\"Loading UNet: {PATH_UNET}\")\n",
    "    m1 = SimpleUNet(NUM_CLASSES).to(DEVICE)\n",
    "    m1.load_state_dict(torch.load(PATH_UNET, map_location=DEVICE), strict=False)\n",
    "    m1.eval()\n",
    "    models['UNet'] = m1\n",
    "    \n",
    "    print(f\"Loading ResNet: {PATH_RESNET}\")\n",
    "    m2 = ResAttnUNetDS(n_classes=NUM_CLASSES, base=48).to(DEVICE)\n",
    "    m2.load_state_dict(torch.load(PATH_RESNET, map_location=DEVICE), strict=False)\n",
    "    m2.eval()\n",
    "    models['ResNet'] = m2\n",
    "\n",
    "    # Find Images\n",
    "    image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, \"raw_*.tiff\")))\n",
    "    if not image_paths: image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, \"raw_*.tif\")))\n",
    "    \n",
    "    print(f\"\\nProcessing {len(image_paths)} images...\")\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        print(f\"\\nTarget: {fname}\")\n",
    "        \n",
    "        try:\n",
    "            raw_img = np.array(Image.open(img_path))\n",
    "            norm_img = robust_normalize(raw_img)\n",
    "            \n",
    "            # Run the \"Fixed\" Inference\n",
    "            pred, ent = run_inference(models, norm_img)\n",
    "            \n",
    "            # Save\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{fname}_fixed_pred.npy\"), pred)\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{fname}_fixed_entropy.npy\"), ent)\n",
    "            \n",
    "            # Visualize\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "            ax[0].imshow(raw_img, cmap=\"gray\"); ax[0].set_title(\"Input\")\n",
    "            \n",
    "            # Plot Fixed Prediction\n",
    "            cmap = plt.get_cmap(\"jet\", NUM_CLASSES)\n",
    "            ax[1].imshow(pred, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1, interpolation='nearest')\n",
    "            ax[1].set_title(f\"Ensemble (ResScale={RESNET_BG_SCALE})\")\n",
    "            \n",
    "            # Plot Entropy\n",
    "            im = ax[2].imshow(ent, cmap=\"inferno\"); ax[2].set_title(\"Uncertainty\")\n",
    "            plt.colorbar(im, ax=ax[2])\n",
    "            \n",
    "            for a in ax: a.axis(\"off\")\n",
    "            plt.savefig(os.path.join(OUTPUT_DIR, f\"{fname}_fixed.png\"), dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ✅ Saved fixed output.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09576433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Lazy ResNet from best_resattn_unet_ds.pth...\n",
      "Preparing Data...\n",
      "Starting Fine-Tune for 5 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 557/557 [03:55<00:00,  2.36it/s, Loss=0.0819]\n",
      "Epoch 2/5: 100%|██████████| 557/557 [03:44<00:00,  2.48it/s, Loss=0.0658]\n",
      "Epoch 3/5: 100%|██████████| 557/557 [03:44<00:00,  2.48it/s, Loss=0.1672]\n",
      "Epoch 4/5: 100%|██████████| 557/557 [03:49<00:00,  2.43it/s, Loss=0.4009]\n",
      "Epoch 5/5: 100%|██████████| 557/557 [04:44<00:00,  1.96it/s, Loss=0.0616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Fine-Tuned Model to best_resattn_finetuned.pth...\n",
      "✅ Done! You can now use this .pth file in the inference script.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIG\n",
    "# ==========================================\n",
    "# Path to the \"Lazy\" ResNet weights\n",
    "LOAD_PATH = \"best_resattn_unet_ds.pth\"\n",
    "SAVE_PATH = \"best_resattn_finetuned.pth\"\n",
    "DATA_DIR  = \"project/processed_tiles\"\n",
    "\n",
    "# Training Config\n",
    "BATCH_SIZE = 4\n",
    "LR = 1e-4  # Low LR to preserve features\n",
    "EPOCHS = 5 # Fast fine-tune\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# --- THE MAGIC FIX ---\n",
    "# We down-weight Background (Class 0) to 0.1.\n",
    "# This tells the model: \"I barely care about background accuracy, \n",
    "# but missing a colored object is a HUGE error.\"\n",
    "CLASS_WEIGHTS = torch.tensor([0.1, 1.0, 1.0, 1.0, 1.0]).to(DEVICE)\n",
    "\n",
    "# ==========================================\n",
    "# 2. MODEL (ResAttnUNetDS)\n",
    "# ==========================================\n",
    "def gn(ch, groups=8):\n",
    "    groups = min(groups, ch)\n",
    "    while groups > 1 and (ch % groups != 0): groups -= 1\n",
    "    return nn.GroupNorm(groups, ch)\n",
    "\n",
    "class ConvGNAct(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, padding=p, bias=False)\n",
    "        self.gn = gn(out_ch); self.act = nn.SiLU(inplace=True)\n",
    "    def forward(self, x): return self.act(self.gn(self.conv(x)))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.c1 = ConvGNAct(in_ch, out_ch)\n",
    "        self.c2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.g2 = gn(out_ch); self.act = nn.SiLU(inplace=True)\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    def forward(self, x): return self.act(self.g2(self.c2(self.c1(x))) + self.skip(x))\n",
    "\n",
    "class AttnGate(nn.Module):\n",
    "    def __init__(self, skip_ch, gate_ch, inter_ch):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Conv2d(skip_ch, inter_ch, 1, bias=False)\n",
    "        self.phi = nn.Conv2d(gate_ch, inter_ch, 1, bias=False)\n",
    "        self.psi = nn.Conv2d(inter_ch, 1, 1, bias=True)\n",
    "        self.act = nn.SiLU(inplace=True); self.sig = nn.Sigmoid()\n",
    "    def forward(self, skip, gate):\n",
    "        g = torch.nn.functional.interpolate(gate, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        return skip * self.sig(self.psi(self.act(self.theta(skip) + self.phi(g))))\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__(); self.pool = nn.MaxPool2d(2); self.block = ResBlock(in_ch, out_ch)\n",
    "    def forward(self, x): return self.block(self.pool(x))\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.reduce = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        self.attn = AttnGate(skip_ch, out_ch, inter_ch=max(16, out_ch // 2))\n",
    "        self.block = ResBlock(out_ch + skip_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x); x = self.reduce(x); skip = self.attn(skip, x)\n",
    "        return self.block(torch.cat([skip, x], dim=1))\n",
    "\n",
    "class ResAttnUNetDS(nn.Module):\n",
    "    def __init__(self, n_classes=5, base=48):\n",
    "        super().__init__()\n",
    "        c1, c2, c3, c4, c5 = base, base*2, base*4, base*8, base*12\n",
    "        self.stem = ResBlock(1, c1)\n",
    "        self.d1 = Down(c1, c2); self.d2 = Down(c2, c3); self.d3 = Down(c3, c4); self.d4 = Down(c4, c5)\n",
    "        self.bottleneck = ResBlock(c5, c5)\n",
    "        self.u3 = Up(c5, c4, c4); self.u2 = Up(c4, c3, c3); self.u1 = Up(c3, c2, c2); self.u0 = Up(c2, c1, c1)\n",
    "        self.head0 = nn.Conv2d(c1, n_classes, 1)\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem(x); s1 = self.d1(s0); s2 = self.d2(s1); s3 = self.d3(s2); s4 = self.d4(s3)\n",
    "        b = self.bottleneck(s4)\n",
    "        x3 = self.u3(b, s3); x2 = self.u2(x3, s2); x1 = self.u1(x2, s1); x0 = self.u0(x1, s0)\n",
    "        return self.head0(x0)\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATASET\n",
    "# ==========================================\n",
    "class TiledNPYDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.img_paths = sorted(glob.glob(os.path.join(root_dir, \"train\", \"images\", \"*.npy\")))\n",
    "        self.msk_paths = sorted(glob.glob(os.path.join(root_dir, \"train\", \"masks\", \"*.npy\")))\n",
    "    def __len__(self): return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        # Using mmap to keep it fast and low RAM\n",
    "        img = np.load(self.img_paths[idx], mmap_mode=\"r\").astype(np.float32)\n",
    "        msk = np.load(self.msk_paths[idx], mmap_mode=\"r\").astype(np.int64)\n",
    "        img = torch.from_numpy(img).float().unsqueeze(0)\n",
    "        msk = torch.from_numpy(msk).long()\n",
    "        # Simple flip augmentation\n",
    "        if np.random.rand() > 0.5: img = TF.hflip(img); msk = TF.hflip(msk)\n",
    "        return img, msk\n",
    "\n",
    "# ==========================================\n",
    "# 4. FINE-TUNE LOOP\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(f\"Loading Lazy ResNet from {LOAD_PATH}...\")\n",
    "    model = ResAttnUNetDS(n_classes=NUM_CLASSES, base=48).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(LOAD_PATH, map_location=DEVICE), strict=False)\n",
    "    \n",
    "    print(\"Preparing Data...\")\n",
    "    ds = TiledNPYDataset(DATA_DIR)\n",
    "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS)\n",
    "    \n",
    "    print(f\"Starting Fine-Tune for {EPOCHS} epochs...\")\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for img, lbl in pbar:\n",
    "            img, lbl = img.to(DEVICE), lbl.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(img)\n",
    "            \n",
    "            # If model returns deep supervision tuple, take the first one\n",
    "            if isinstance(logits, tuple): logits = logits[0]\n",
    "                \n",
    "            loss = criterion(logits, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "    print(f\"Saving Fine-Tuned Model to {SAVE_PATH}...\")\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    print(\"✅ Done! You can now use this .pth file in the inference script.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655baf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet from best_resattn_finetuned.pth...\n",
      "\n",
      "Processing raw_13...\n",
      "  > Processing Single Pass at 1.25x Zoom (6213x6901)...\n",
      "  ✅ Saved results to C:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\test_data_tiff\\outputs_fast_boost\\raw_13ResNet_FastBoost.png\n",
      "\n",
      "Processing raw_14...\n",
      "  > Processing Single Pass at 1.25x Zoom (1783x1453)...\n",
      "  ✅ Saved results to C:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\test_data_tiff\\outputs_fast_boost\\raw_14ResNet_FastBoost.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "\n",
    "# ==========================================\n",
    "# 1. OPTIMIZED CONFIGURATION\n",
    "# ==========================================\n",
    "# Use the fine-tuned model if available\n",
    "MODEL_PATH = \"best_resattn_finetuned.pth\" \n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    MODEL_PATH = \"best_resattn_unet_ds.pth\"\n",
    "\n",
    "TEST_DATA_DIR = r\"C:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\test_data_tiff\"\n",
    "OUTPUT_DIR = os.path.join(TEST_DATA_DIR, \"outputs_fast_boost\")\n",
    "\n",
    "\n",
    "STRIDE = 256 \n",
    "TILE_SIZE = 512\n",
    "\n",
    "\n",
    "ZOOM_LEVEL = 1.25 \n",
    "\n",
    "BG_SUPPRESSION = 0.4\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "\n",
    "def gn(ch, groups=8):\n",
    "    groups = min(groups, ch)\n",
    "    while groups > 1 and (ch % groups != 0): groups -= 1\n",
    "    return nn.GroupNorm(groups, ch)\n",
    "\n",
    "class ConvGNAct(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, padding=p, bias=False)\n",
    "        self.gn = gn(out_ch); self.act = nn.SiLU(inplace=True)\n",
    "    def forward(self, x): return self.act(self.gn(self.conv(x)))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.c1 = ConvGNAct(in_ch, out_ch)\n",
    "        self.c2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.g2 = gn(out_ch); self.act = nn.SiLU(inplace=True)\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    def forward(self, x): return self.act(self.g2(self.c2(self.c1(x))) + self.skip(x))\n",
    "\n",
    "class AttnGate(nn.Module):\n",
    "    def __init__(self, skip_ch, gate_ch, inter_ch):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Conv2d(skip_ch, inter_ch, 1, bias=False)\n",
    "        self.phi = nn.Conv2d(gate_ch, inter_ch, 1, bias=False)\n",
    "        self.psi = nn.Conv2d(inter_ch, 1, 1, bias=True)\n",
    "        self.act = nn.SiLU(inplace=True); self.sig = nn.Sigmoid()\n",
    "    def forward(self, skip, gate):\n",
    "        g = F.interpolate(gate, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        return skip * self.sig(self.psi(self.act(self.theta(skip) + self.phi(g))))\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__(); self.pool = nn.MaxPool2d(2); self.block = ResBlock(in_ch, out_ch)\n",
    "    def forward(self, x): return self.block(self.pool(x))\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.reduce = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        self.attn = AttnGate(skip_ch, out_ch, inter_ch=max(16, out_ch // 2))\n",
    "        self.block = ResBlock(out_ch + skip_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x); x = self.reduce(x); skip = self.attn(skip, x)\n",
    "        return self.block(torch.cat([skip, x], dim=1))\n",
    "\n",
    "class ResAttnUNetDS(nn.Module):\n",
    "    def __init__(self, n_classes=5, base=48):\n",
    "        super().__init__()\n",
    "        c1, c2, c3, c4, c5 = base, base*2, base*4, base*8, base*12\n",
    "        self.stem = ResBlock(1, c1)\n",
    "        self.d1 = Down(c1, c2); self.d2 = Down(c2, c3); self.d3 = Down(c3, c4); self.d4 = Down(c4, c5)\n",
    "        self.bottleneck = ResBlock(c5, c5)\n",
    "        self.u3 = Up(c5, c4, c4); self.u2 = Up(c4, c3, c3); self.u1 = Up(c3, c2, c2); self.u0 = Up(c2, c1, c1)\n",
    "        self.head0 = nn.Conv2d(c1, n_classes, 1)\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem(x); s1 = self.d1(s0); s2 = self.d2(s1); s3 = self.d3(s2); s4 = self.d4(s3)\n",
    "        b = self.bottleneck(s4)\n",
    "        x3 = self.u3(b, s3); x2 = self.u2(x3, s2); x1 = self.u1(x2, s1); x0 = self.u0(x1, s0)\n",
    "        return self.head0(x0)\n",
    "\n",
    "\n",
    "def robust_normalize(img):\n",
    "    img = img.astype(np.float32)\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    if p98 - p2 < 1e-6: return np.zeros_like(img, dtype=np.float32)\n",
    "    img = (img - p2) / (p98 - p2)\n",
    "    return np.clip(img, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def calculate_entropy(probs):\n",
    "    epsilon = 1e-6\n",
    "    entropy = -torch.sum(probs * torch.log(probs + epsilon), dim=0)\n",
    "    return entropy\n",
    "\n",
    "def predict_on_array(model, img_arr, stride):\n",
    "    \"\"\"\n",
    "    Standard sliding window inference on a specific numpy array\n",
    "    \"\"\"\n",
    "    h, w = img_arr.shape\n",
    "    prob_sum = torch.zeros((NUM_CLASSES, h, w), dtype=torch.float32, device=DEVICE)\n",
    "    count_map = torch.zeros((1, h, w), dtype=torch.float32, device=DEVICE)\n",
    "    \n",
    "    y_starts = sorted(list(set(list(range(0, h, stride)) + [max(0, h - TILE_SIZE)])))\n",
    "    x_starts = sorted(list(set(list(range(0, w, stride)) + [max(0, w - TILE_SIZE)])))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for y in y_starts:\n",
    "            for x in x_starts:\n",
    "                y_end, x_end = min(y + TILE_SIZE, h), min(x + TILE_SIZE, w)\n",
    "                tile = img_arr[y:y_end, x:x_end]\n",
    "                th, tw = tile.shape\n",
    "                \n",
    "                pad_h, pad_w = TILE_SIZE - th, TILE_SIZE - tw\n",
    "                if pad_h > 0 or pad_w > 0:\n",
    "                    tile = np.pad(tile, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
    "\n",
    "                inp = torch.from_numpy(tile).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "                logits = model(inp)\n",
    "                if isinstance(logits, tuple): logits = logits[0]\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                \n",
    "                probs = probs[0, :, :th, :tw]\n",
    "                prob_sum[:, y:y_end, x:x_end] += probs\n",
    "                count_map[:, y:y_end, x:x_end] += 1.0\n",
    "                \n",
    "    return prob_sum / count_map\n",
    "\n",
    "def fast_boost_inference(model, raw_img):\n",
    "    \"\"\"\n",
    "    Runs Single-Pass Zoomed Inference\n",
    "    \"\"\"\n",
    "    orig_h, orig_w = raw_img.shape\n",
    "\n",
    "    target_h, target_w = int(orig_h * ZOOM_LEVEL), int(orig_w * ZOOM_LEVEL)\n",
    "    print(f\"  > Processing Single Pass at {ZOOM_LEVEL}x Zoom ({target_w}x{target_h})...\")\n",
    "    \n",
    "    scaled_img = cv2.resize(raw_img, (target_w, target_h), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "\n",
    "    scaled_probs = predict_on_array(model, scaled_img, stride=STRIDE)\n",
    "    \n",
    "\n",
    "    scaled_probs_t = scaled_probs.unsqueeze(0) \n",
    "    \n",
    "    final_probs = F.interpolate(\n",
    "        scaled_probs_t, \n",
    "        size=(orig_h, orig_w), \n",
    "        mode='bilinear', \n",
    "        align_corners=False\n",
    "    )[0] \n",
    "\n",
    "    if BG_SUPPRESSION < 1.0:\n",
    "        final_probs[0, :, :] *= BG_SUPPRESSION\n",
    "        final_probs = final_probs / final_probs.sum(dim=0, keepdim=True)\n",
    "        \n",
    "    return final_probs\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    print(f\"Loading ResNet from {MODEL_PATH}...\")\n",
    "    model = ResAttnUNetDS(n_classes=NUM_CLASSES, base=48).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, \"raw_*.tiff\")))\n",
    "    if not image_paths: image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, \"raw_*.tif\")))\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        print(f\"\\nProcessing {fname}...\")\n",
    "        \n",
    "        try:\n",
    "            raw_img = np.array(Image.open(img_path))\n",
    "            norm_img = robust_normalize(raw_img)\n",
    "\n",
    "            probs = fast_boost_inference(model, norm_img)\n",
    "\n",
    "            pred = torch.argmax(probs, dim=0).cpu().numpy().astype(np.uint8)\n",
    "            ent = calculate_entropy(probs).cpu().numpy()\n",
    " \n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{fname}_boost_pred.npy\"), pred)\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{fname}_boost_entropy.npy\"), ent)\n",
    "            \n",
    " \n",
    "            fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "            ax[0].imshow(raw_img, cmap=\"gray\"); ax[0].set_title(\"Input\")\n",
    "            \n",
    "            cmap = plt.get_cmap(\"jet\", NUM_CLASSES)\n",
    "            ax[1].imshow(pred, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1, interpolation='nearest')\n",
    "            ax[1].set_title(f\"ResNet Fast Boost (Zoom={ZOOM_LEVEL}x) Prediction\")\n",
    "            \n",
    "            im = ax[2].imshow(ent, cmap=\"inferno\"); ax[2].set_title(\"ResNet Entropy\")\n",
    "            plt.colorbar(im, ax=ax[2])\n",
    "            \n",
    "            for a in ax: a.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(OUTPUT_DIR, f\"{fname}ResNet_FastBoost.png\")\n",
    "            plt.savefig(save_path, dpi=150)\n",
    "            plt.close()\n",
    "            print(f\"  ✅ Saved results to {save_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca9281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SimpleUNet from project/best_unet_godmode_v2.pth...\n",
      "✅ Model loaded.\n",
      "\n",
      "Processing raw_13...\n",
      "  > Processing 210 tiles...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "CHECKPOINT_PATH = \"project/best_unet_godmode_v2.pth\"\n",
    "\n",
    "TEST_DATA_DIR = r\"C:\\Users\\vonkl\\Documents\\453_Project\\453_Project\\project\\test_data_tiff\"\n",
    "OUTPUT_DIR = os.path.join(TEST_DATA_DIR, \"outputs_unet_only\")\n",
    "\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "TILE_SIZE = 512\n",
    "STRIDE = 400\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class DoubleConvGN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConvGN(1, 64)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN(64, 128))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN(128, 256))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConvGN(256, 512))\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        self.conv1 = DoubleConvGN(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        self.conv2 = DoubleConvGN(256, 128)\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        self.conv3 = DoubleConvGN(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        \n",
    "        x = self.up1(x4)\n",
    "        x = torch.cat([x3, x], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "        x = self.conv3(x)\n",
    "        return self.outc(x)\n",
    "\n",
    "def robust_normalize(img):\n",
    "    \"\"\"Normalizes based on 2nd and 98th percentiles.\"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    if p98 - p2 < 1e-6:\n",
    "        return np.zeros_like(img, dtype=np.float32)\n",
    "    img = (img - p2) / (p98 - p2)\n",
    "    return np.clip(img, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def calculate_entropy(probs):\n",
    "    \"\"\"Entropy = - sum(p * log(p))\"\"\"\n",
    "    epsilon = 1e-6\n",
    "    entropy = -torch.sum(probs * torch.log(probs + epsilon), dim=0)\n",
    "    return entropy\n",
    "\n",
    "def sliding_window_inference(model, img_array, tile_size, stride, num_classes, device):\n",
    "    \"\"\"\n",
    "    Runs sliding window inference on a large image.\n",
    "    \"\"\"\n",
    "    h, w = img_array.shape\n",
    "    prob_sum = torch.zeros((num_classes, h, w), dtype=torch.float32, device=device)\n",
    "    count_map = torch.zeros((1, h, w), dtype=torch.float32, device=device)\n",
    "    \n",
    "   \n",
    "    y_starts = sorted(list(set(list(range(0, h, stride)) + [max(0, h - tile_size)])))\n",
    "    x_starts = sorted(list(set(list(range(0, w, stride)) + [max(0, w - tile_size)])))\n",
    "\n",
    "    print(f\"  > Processing {len(y_starts) * len(x_starts)} tiles...\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for y in y_starts:\n",
    "            for x in x_starts:\n",
    "                y_end, x_end = min(y + tile_size, h), min(x + tile_size, w)\n",
    "                tile = img_array[y:y_end, x:x_end]\n",
    "                th, tw = tile.shape\n",
    "\n",
    "                pad_h, pad_w = tile_size - th, tile_size - tw\n",
    "                if pad_h > 0 or pad_w > 0:\n",
    "                    tile = np.pad(tile, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
    "\n",
    "\n",
    "                input_tensor = torch.from_numpy(tile).unsqueeze(0).unsqueeze(0).to(device)\n",
    "                logits = model(input_tensor)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "       \n",
    "                probs = probs[0, :, :th, :tw]\n",
    "                prob_sum[:, y:y_end, x:x_end] += probs\n",
    "                count_map[:, y:y_end, x:x_end] += 1.0\n",
    "\n",
    "\n",
    "    avg_probs = prob_sum / count_map\n",
    "    \n",
    "\n",
    "    pred_map = torch.argmax(avg_probs, dim=0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    ent_map = calculate_entropy(avg_probs).cpu().numpy()\n",
    "    \n",
    "    return pred_map, ent_map\n",
    "\n",
    "\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    print(f\"Loading SimpleUNet from {CHECKPOINT_PATH}...\")\n",
    "    if not os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f\"❌ Error: Model file not found at {CHECKPOINT_PATH}\")\n",
    "        return\n",
    "\n",
    "    model = SimpleUNet(n_classes=NUM_CLASSES).to(DEVICE)\n",
    "    try:\n",
    "       \n",
    "        model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE), strict=False)\n",
    "        print(\"✅ Model loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load weights: {e}\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, \"raw_*.tiff\")))\n",
    "    if not image_paths:\n",
    "        image_paths = sorted(glob.glob(os.path.join(TEST_DATA_DIR, \"raw_*.tif\")))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(\"❌ No images found in test_data_tiff folder.\")\n",
    "        return\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        print(f\"\\nProcessing {fname}...\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            raw_img = np.array(Image.open(img_path))\n",
    "            norm_img = robust_normalize(raw_img)\n",
    "            \n",
    "     \n",
    "            pred_mask, entropy_map = sliding_window_inference(\n",
    "                model, norm_img, TILE_SIZE, STRIDE, NUM_CLASSES, DEVICE\n",
    "            )\n",
    "            \n",
    "          \n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{fname}_pred.npy\"), pred_mask)\n",
    "            np.save(os.path.join(OUTPUT_DIR, f\"{fname}_entropy.npy\"), entropy_map)\n",
    "            \n",
    "        \n",
    "            fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "            \n",
    "        \n",
    "            ax[0].imshow(raw_img, cmap=\"gray\")\n",
    "            ax[0].set_title(\"Input Image\")\n",
    "            ax[0].axis(\"off\")\n",
    "            \n",
    "   \n",
    "            cmap = plt.get_cmap(\"jet\", NUM_CLASSES)\n",
    "            ax[1].imshow(pred_mask, cmap=cmap, vmin=0, vmax=NUM_CLASSES-1, interpolation='nearest')\n",
    "            ax[1].set_title(\"UNet Prediction\")\n",
    "            ax[1].axis(\"off\")\n",
    "            \n",
    "      \n",
    "            im = ax[2].imshow(entropy_map, cmap=\"inferno\")\n",
    "            ax[2].set_title(\"Entropy (Uncertainty)\")\n",
    "            ax[2].axis(\"off\")\n",
    "            plt.colorbar(im, ax=ax[2], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            save_vis = os.path.join(OUTPUT_DIR, f\"{fname}_unet_result.png\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_vis, dpi=150)\n",
    "            plt.close()\n",
    "            print(f\"✅ Saved results to {save_vis}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {fname}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb36a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c136e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os, glob, random, shutil, math, time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ORIGINAL_DATA_DIR = \"project/train_data_tiff\"\n",
    "PROCESSED_DIR     = \"project/processed_tiles\"\n",
    "\n",
    "TILE_SIZE = 512\n",
    "STRIDE = 400\n",
    "CLASS_VALUES = [0, 50, 100, 150, 200]\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "ACCUM_STEPS = 4\n",
    "LR = 3e-4\n",
    "EPOCHS = 30\n",
    "BASE_CH = 48\n",
    "USE_AMP = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def cleanup_dir(d):\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def robust_normalize(img):\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    if p98 - p2 < 1e-6:\n",
    "        return np.zeros_like(img, dtype=np.float32)\n",
    "    img = (img - p2) / (p98 - p2)\n",
    "    return np.clip(img, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def map_labels_nearest(lbl_arr):\n",
    "    \n",
    "    lbl = lbl_arr.astype(np.int32)\n",
    "    diffs = np.abs(lbl[..., None] - np.array(CLASS_VALUES)[None, None, :])\n",
    "    return diffs.argmin(axis=-1).astype(np.uint8) \n",
    "\n",
    "def compute_starts(L, tile, stride):\n",
    "    if L <= tile:\n",
    "        return [0]\n",
    "    starts = list(range(0, L - tile + 1, stride))\n",
    "    if starts[-1] != L - tile:\n",
    "        starts.append(L - tile)\n",
    "    return starts\n",
    "\n",
    "def find_raw_files(data_dir):\n",
    "    exts = (\".tif\", \".tiff\", \".png\")\n",
    "    candidates = sorted(glob.glob(os.path.join(data_dir, \"raw_*\")))\n",
    "    raws = [p for p in candidates if os.path.splitext(p)[1].lower() in exts]\n",
    "    if len(raws) == 0:\n",
    "     \n",
    "        candidates = sorted(glob.glob(os.path.join(data_dir, \"*\")))\n",
    "        raws = [p for p in candidates if (\"raw\" in os.path.basename(p).lower()) and (os.path.splitext(p)[1].lower() in exts)]\n",
    "    return sorted(raws)\n",
    "\n",
    "def corresponding_label_path(raw_path):\n",
    "\n",
    "    dn = os.path.dirname(raw_path)\n",
    "    bn = os.path.basename(raw_path)\n",
    "\n",
    "    p1 = os.path.join(dn, bn.replace(\"raw_\", \"label_\", 1))\n",
    "    if os.path.exists(p1):\n",
    "        return p1\n",
    "\n",
    "    if bn.startswith(\"raw_\"):\n",
    "        p2 = os.path.join(dn, \"label_\" + bn[len(\"raw_\"):])\n",
    "        if os.path.exists(p2):\n",
    "            return p2\n",
    "    return None\n",
    "\n",
    "def tile_and_save(raw_paths, out_dir, subset):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "\n",
    "    os.makedirs(os.path.join(out_dir, subset, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(out_dir, subset, \"masks\"), exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    for raw_p in raw_paths:\n",
    "        base = os.path.splitext(os.path.basename(raw_p))[0]\n",
    "\n",
    "        lbl_p = raw_p.replace(\"raw_\", \"label_\")\n",
    "        if not os.path.exists(lbl_p):\n",
    "            lbl_p = os.path.join(os.path.dirname(raw_p), \"label_\" + base.replace(\"raw_\", \"\") + \".tif\")\n",
    "        if not os.path.exists(lbl_p):\n",
    "            lbl_p = os.path.join(os.path.dirname(raw_p), \"label_\" + base.replace(\"raw_\", \"\") + \".tiff\")\n",
    "        if not os.path.exists(lbl_p):\n",
    "            continue\n",
    "\n",
    "        raw = robust_normalize(np.array(Image.open(raw_p)))\n",
    "        lbl = map_labels_nearest(np.array(Image.open(lbl_p)))\n",
    "\n",
    "        h, w = raw.shape\n",
    "        ys = compute_starts(h, TILE_SIZE, STRIDE)\n",
    "        xs = compute_starts(w, TILE_SIZE, STRIDE)\n",
    "\n",
    "        for y in ys:\n",
    "            for x in xs:\n",
    "                img_tile = raw[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "                lbl_tile = lbl[y:y+TILE_SIZE, x:x+TILE_SIZE]\n",
    "\n",
    "                unique = np.unique(lbl_tile)\n",
    "\n",
    "                if subset == \"val\":\n",
    "                    keep = True\n",
    "                else:\n",
    "                    keep = True\n",
    "                    if len(unique) == 1 and unique[0] == 0:\n",
    "                        keep = (random.random() < 0.10)  \n",
    "                    if (3 in unique) or (4 in unique) or (1 in unique):\n",
    "                        keep = True\n",
    "\n",
    "                if keep:\n",
    "                    np.save(os.path.join(out_dir, subset, \"images\", f\"tile_{count}.npy\"),\n",
    "                            img_tile.astype(np.float32))\n",
    "    \n",
    "                    np.save(os.path.join(out_dir, subset, \"masks\", f\"tile_{count}.npy\"),\n",
    "                            lbl_tile.astype(np.uint8))\n",
    "                    count += 1\n",
    "\n",
    "    print(f\"[{subset}] saved tiles: {count}\")\n",
    "\n",
    "\n",
    "def class_frequencies_from_tiles(processed_dir, subset, num_classes=5):\n",
    "    import glob, os, numpy as np\n",
    "    mpaths = sorted(glob.glob(os.path.join(processed_dir, subset, \"masks\", \"*.npy\")))\n",
    "    counts = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    for p in mpaths:\n",
    "        m = np.load(p, mmap_mode=\"r\")\n",
    "        bc = np.bincount(m.reshape(-1), minlength=num_classes)\n",
    "        counts[:num_classes] += bc[:num_classes]\n",
    "\n",
    "    total = counts.sum()\n",
    "    freqs = counts / (total + 1e-12)\n",
    "    return counts, freqs, total, len(mpaths)\n",
    "\n",
    "\n",
    "class TiledNPYDataset(Dataset):\n",
    "    def __init__(self, root_dir, subset=\"train\"):\n",
    "        self.subset = subset\n",
    "        self.img_paths = sorted(glob.glob(os.path.join(root_dir, subset, \"images\", \"*.npy\")))\n",
    "        self.msk_paths = sorted(glob.glob(os.path.join(root_dir, subset, \"masks\", \"*.npy\")))\n",
    "        assert len(self.img_paths) == len(self.msk_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.load(self.img_paths[idx], mmap_mode=\"r\").astype(np.float32)\n",
    "        msk = np.load(self.msk_paths[idx], mmap_mode=\"r\")  \n",
    "\n",
    "        img = torch.from_numpy(img).float().unsqueeze(0)\n",
    "        msk = torch.from_numpy(msk).long()\n",
    "\n",
    "        if self.subset == \"train\":\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.hflip(img); msk = TF.hflip(msk)\n",
    "            if random.random() < 0.5:\n",
    "                img = TF.vflip(img); msk = TF.vflip(msk)\n",
    "            if random.random() < 0.3:\n",
    "                img = torch.clamp(img + 0.05 * torch.randn_like(img), 0.0, 1.0)\n",
    "\n",
    "        return img, msk\n",
    "\n",
    "\n",
    "def smoke_test_loader(loader):\n",
    "    t0 = time.time()\n",
    "    batch = next(iter(loader))\n",
    "    print(\"First batch fetched in\", round(time.time()-t0, 2), \"sec\",\n",
    "          \"| img\", batch[0].shape, \"| msk\", batch[1].shape)\n",
    "\n",
    "\n",
    "def gn(ch, groups=8):\n",
    "    groups = min(groups, ch)\n",
    "    while groups > 1 and (ch % groups != 0):\n",
    "        groups -= 1\n",
    "    return nn.GroupNorm(groups, ch)\n",
    "\n",
    "class ConvGNAct(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, k, padding=p, bias=False)\n",
    "        self.gn = gn(out_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        return self.act(self.gn(self.conv(x)))\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.c1 = ConvGNAct(in_ch, out_ch)\n",
    "        self.c2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.g2 = gn(out_ch)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        h = self.c1(x)\n",
    "        h = self.g2(self.c2(h))\n",
    "        return self.act(h + self.skip(x))\n",
    "\n",
    "class AttnGate(nn.Module):\n",
    "    def __init__(self, skip_ch, gate_ch, inter_ch):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Conv2d(skip_ch, inter_ch, 1, bias=False)\n",
    "        self.phi   = nn.Conv2d(gate_ch, inter_ch, 1, bias=False)\n",
    "        self.psi   = nn.Conv2d(inter_ch, 1, 1, bias=True)\n",
    "        self.act   = nn.SiLU(inplace=True)\n",
    "        self.sig   = nn.Sigmoid()\n",
    "    def forward(self, skip, gate):\n",
    "        g = F.interpolate(gate, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        a = self.act(self.theta(skip) + self.phi(g))\n",
    "        a = self.sig(self.psi(a))\n",
    "        return skip * a\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.block = ResBlock(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        return self.block(self.pool(x))\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.reduce = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "    \n",
    "        self.attn = AttnGate(skip_ch, out_ch, inter_ch=max(16, out_ch // 2))\n",
    "        self.block = ResBlock(out_ch + skip_ch, out_ch)\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = self.reduce(x)\n",
    "        skip = self.attn(skip, x)\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "class ResAttnUNetDS(nn.Module):\n",
    "    def __init__(self, n_classes=NUM_CLASSES, base=48):\n",
    "        super().__init__()\n",
    "        c1, c2, c3, c4, c5 = base, base*2, base*4, base*8, base*12\n",
    "\n",
    "        self.stem = ResBlock(1, c1)     \n",
    "        self.d1 = Down(c1, c2)          \n",
    "        self.d2 = Down(c2, c3)          \n",
    "        self.d3 = Down(c3, c4)          \n",
    "        self.d4 = Down(c4, c5)       \n",
    "\n",
    "        self.bottleneck = ResBlock(c5, c5)  \n",
    "\n",
    "        self.u3 = Up(c5, c4, c4)       \n",
    "        self.u2 = Up(c4, c3, c3)        \n",
    "        self.u1 = Up(c3, c2, c2)         \n",
    "        self.u0 = Up(c2, c1, c1)        \n",
    "\n",
    "        self.head0 = nn.Conv2d(c1, n_classes, 1)  \n",
    "        self.head1 = nn.Conv2d(c2, n_classes, 1) \n",
    "        self.head2 = nn.Conv2d(c3, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem(x)\n",
    "        s1 = self.d1(s0)\n",
    "        s2 = self.d2(s1)\n",
    "        s3 = self.d3(s2)\n",
    "        s4 = self.d4(s3)\n",
    "\n",
    "        b  = self.bottleneck(s4)\n",
    "\n",
    "        x3 = self.u3(b,  s3)\n",
    "        x2 = self.u2(x3, s2)\n",
    "        x1 = self.u1(x2, s1)\n",
    "        x0 = self.u0(x1, s0)\n",
    "\n",
    "        out0 = self.head0(x0)\n",
    "        out1 = self.head1(x1)\n",
    "        out2 = self.head2(x2)\n",
    "        return out0, out1, out2\n",
    "\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, n_classes, include_bg=False, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.include_bg = include_bg\n",
    "        self.eps = eps\n",
    "    def forward(self, logits, target):\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        tgt = F.one_hot(target, num_classes=self.n_classes).permute(0,3,1,2).float()\n",
    "        if not self.include_bg:\n",
    "            probs = probs[:, 1:]\n",
    "            tgt   = tgt[:, 1:]\n",
    "        dims = (0,2,3)\n",
    "        inter = (probs * tgt).sum(dims)\n",
    "        union = probs.sum(dims) + tgt.sum(dims)\n",
    "        dice = (2*inter + self.eps) / (union + self.eps)\n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "class ComboLoss(nn.Module):\n",
    "    def __init__(self, class_weights, dice_w=0.6, ce_w=0.4):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.dice = SoftDiceLoss(n_classes=len(class_weights), include_bg=False)\n",
    "        self.dice_w = dice_w\n",
    "        self.ce_w = ce_w\n",
    "    def forward(self, logits, target):\n",
    "        return self.ce_w * self.ce(logits, target) + self.dice_w * self.dice(logits, target)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def macro_dice_ex_bg(pred, tgt, n_classes=NUM_CLASSES, eps=1e-6):\n",
    "    dices=[]\n",
    "    for c in range(1, n_classes):\n",
    "        p = (pred==c).float()\n",
    "        t = (tgt==c).float()\n",
    "        d = (2*(p*t).sum() + eps) / (p.sum() + t.sum() + eps)\n",
    "        dices.append(d.item())\n",
    "    return float(np.mean(dices)) if dices else 0.0\n",
    "\n",
    "\n",
    "def compute_class_weights_from_mask_files(mask_paths, n_classes, device):\n",
    "    counts = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "    for p in mask_paths:\n",
    "        m = np.load(p, mmap_mode=\"r\")\n",
    "        bc = np.bincount(m.reshape(-1), minlength=n_classes)\n",
    "        counts[:n_classes] += bc[:n_classes]\n",
    "\n",
    "    freq = counts / (counts.sum() + 1e-12)\n",
    "    w = 1.0 / np.sqrt(freq + 1e-12)\n",
    "\n",
    "\n",
    "    w[0] = 0.2\n",
    "\n",
    "    w = w / w.mean()\n",
    "    return torch.tensor(w, device=device).float()\n",
    "\n",
    "\n",
    "def train(\n",
    "    processed_dir,\n",
    "    epochs = 30,\n",
    "    batch_size=4,\n",
    "    accum_steps=4,\n",
    "    lr=3e-4,\n",
    "    base_ch=48,\n",
    "    use_amp=True,\n",
    "    device=\"cuda\",\n",
    "    num_workers=0,\n",
    "):\n",
    "  \n",
    "    DO_FULL_VAL_EVERY = 10     \n",
    "    FAST_VAL_BATCHES  = 50    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fast_val(model, val_loader, device, n_batches):\n",
    "        model.eval()\n",
    "        dices = []\n",
    "        for b, (img, msk) in enumerate(val_loader):\n",
    "            if b >= n_batches:\n",
    "                break\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            msk = msk.to(device, non_blocking=True)\n",
    "            out0, _, _ = model(img)\n",
    "            pred = out0.argmax(dim=1)\n",
    "            dices.append(macro_dice_ex_bg(pred, msk, n_classes=NUM_CLASSES))\n",
    "        return float(np.mean(dices)) if dices else 0.0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def full_val(model, val_loader, device):\n",
    "        model.eval()\n",
    "        dices = []\n",
    "        for img, msk in val_loader:\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            msk = msk.to(device, non_blocking=True)\n",
    "            out0, _, _ = model(img)\n",
    "            pred = out0.argmax(dim=1)\n",
    "            dices.append(macro_dice_ex_bg(pred, msk, n_classes=NUM_CLASSES))\n",
    "        return float(np.mean(dices)) if dices else 0.0\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    amp_on = (use_amp and str(device).startswith(\"cuda\"))\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=amp_on)\n",
    "\n",
    "    train_ds = TiledNPYDataset(processed_dir, \"train\")\n",
    "    val_ds   = TiledNPYDataset(processed_dir, \"val\")\n",
    "\n",
    "\n",
    "    class_w = compute_class_weights_from_mask_files(train_ds.msk_paths, NUM_CLASSES, device)\n",
    "\n",
    "\n",
    "    w_path = os.path.join(processed_dir, \"train\", \"tile_weights.npy\")\n",
    "    if not os.path.exists(w_path):\n",
    "        build_and_save_tile_weights(processed_dir, \"train\", num_classes=NUM_CLASSES)\n",
    "    tile_weights = np.load(w_path)\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.DoubleTensor(tile_weights),\n",
    "        num_samples=len(tile_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, sampler=sampler,\n",
    "        num_workers=num_workers, pin_memory=str(device).startswith(\"cuda\")\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=str(device).startswith(\"cuda\")\n",
    "    )\n",
    "\n",
    "    smoke_test_loader(train_loader)\n",
    "\n",
    "    model = ResAttnUNetDS(n_classes=NUM_CLASSES, base=base_ch).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    steps_per_epoch = math.ceil(len(train_loader) / accum_steps)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt, max_lr=lr, epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "    )\n",
    "\n",
    "    criterion = ComboLoss(class_w, dice_w=0.7, ce_w=0.3)\n",
    "\n",
    "    best = -1.0\n",
    "    best_is_full = False\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {ep+1}/{epochs}\")\n",
    "        for i, (img, msk) in pbar:\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            msk = msk.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=amp_on):\n",
    "                out0, out1, out2 = model(img)\n",
    "\n",
    "                m1 = F.interpolate(msk.unsqueeze(1).float(), scale_factor=0.5, mode=\"nearest\").squeeze(1).long()\n",
    "                m2 = F.interpolate(msk.unsqueeze(1).float(), scale_factor=0.25, mode=\"nearest\").squeeze(1).long()\n",
    "\n",
    "                loss0 = criterion(out0, msk)\n",
    "                loss1 = criterion(out1, m1)\n",
    "                loss2 = criterion(out2, m2)\n",
    "\n",
    "                loss = (loss0 + 0.5*loss1 + 0.25*loss2) / accum_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % accum_steps == 0:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                sched.step()\n",
    "\n",
    "            run_loss += loss.item() * accum_steps\n",
    "            pbar.set_postfix(loss=f\"{run_loss/(i+1):.4f}\", lr=f\"{sched.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        train_loss_ep = run_loss / max(1, len(train_loader))\n",
    "\n",
    "        if (ep + 1) % DO_FULL_VAL_EVERY == 0:\n",
    "            val_d = full_val(model, val_loader, device)\n",
    "            is_full = True\n",
    "            print(f\"Epoch {ep+1}: train_loss={train_loss_ep:.4f}  FULL val_macroDice(ex-bg)={val_d:.4f}\")\n",
    "        else:\n",
    "            val_d = fast_val(model, val_loader, device, FAST_VAL_BATCHES)\n",
    "            is_full = False\n",
    "            print(f\"Epoch {ep+1}: train_loss={train_loss_ep:.4f}  fast val_macroDice(ex-bg)~={val_d:.4f} ({FAST_VAL_BATCHES} batches)\")\n",
    "\n",
    " \n",
    "        if val_d > best:\n",
    "            best = val_d\n",
    "            best_is_full = is_full\n",
    "            torch.save(model.state_dict(), \"best_resattn_unet_ds.pth\")\n",
    "            tag = \"FULL\" if is_full else \"FAST\"\n",
    "            print(f\"   saved best ({tag}): {best:.4f}\")\n",
    "\n",
    "    print(\"Best val dice:\", best, \"| based on\", (\"FULL\" if best_is_full else \"FAST\"))\n",
    "\n",
    "\n",
    "\n",
    "def build_and_save_tile_weights(processed_dir, subset=\"train\", num_classes=5,\n",
    "                                w_c4=10.0, w_c1=4.0, w_c3=2.0, w_pure_bg=0.25):\n",
    "    import os, glob\n",
    "    import numpy as np\n",
    "\n",
    "    mpaths = sorted(glob.glob(os.path.join(processed_dir, subset, \"masks\", \"*.npy\")))\n",
    "    weights = np.ones(len(mpaths), dtype=np.float32)\n",
    "\n",
    "    for i, p in enumerate(mpaths):\n",
    "        m = np.load(p, mmap_mode=\"r\")  \n",
    "        bc = np.bincount(m.reshape(-1), minlength=num_classes)\n",
    "\n",
    "        w = 1.0\n",
    "        if bc[4] > 0: w *= w_c4\n",
    "        if bc[1] > 0: w *= w_c1\n",
    "        if bc[3] > 0: w *= w_c3\n",
    "        if bc[0] == m.size: w *= w_pure_bg\n",
    "        weights[i] = w\n",
    "\n",
    "    out_path = os.path.join(processed_dir, subset, \"tile_weights.npy\")\n",
    "    np.save(out_path, weights)\n",
    "    print(f\"Saved {len(weights)} sampling weights -> {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def split_images(raw_paths, val_split=VAL_SPLIT, seed=SEED):\n",
    "    idx = list(range(len(raw_paths)))\n",
    "    rng = random.Random(seed)\n",
    "    rng.shuffle(idx)\n",
    "    n_val = max(1, int(round(len(raw_paths) * val_split))) if len(raw_paths) > 1 else 0\n",
    "    val_idx = set(idx[:n_val])\n",
    "    train_paths = [raw_paths[i] for i in range(len(raw_paths)) if i not in val_idx]\n",
    "    val_paths   = [raw_paths[i] for i in range(len(raw_paths)) if i in val_idx]\n",
    "    return train_paths, val_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_exists(processed_dir):\n",
    "    return (\n",
    "        len(glob.glob(os.path.join(processed_dir, \"train\", \"images\", \"*.npy\"))) > 0 and\n",
    "        len(glob.glob(os.path.join(processed_dir, \"val\", \"images\", \"*.npy\"))) > 0 and\n",
    "        os.path.exists(os.path.join(processed_dir, \"train\", \"tile_weights.npy\"))\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ee97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMAGE SPLIT ===\n",
      "Train raw images: 9\n",
      "Val raw images:   2\n",
      "Train files: ['raw_01.tiff', 'raw_02.tiff', 'raw_04.tiff', 'raw_06.tiff', 'raw_07.tiff', 'raw_08.tiff', 'raw_10.tiff', 'raw_11.tiff', 'raw_12.tiff']\n",
      "Val files:   ['raw_05.tiff', 'raw_09.tiff']\n",
      "\n",
      "[cache hit] using existing tiles in: project/processed_tiles\n",
      "\n",
      "=== TILE COUNTS ===\n",
      "Train tiles: 2226\n",
      "Val tiles:   782\n",
      "\n",
      "=== TRAIN CLASS FREQUENCIES ===\n",
      "Tiles: 2226 | Total pixels: 583,532,544\n",
      "  Class 0: 279,387,728 px  (47.879%)\n",
      "  Class 1: 28,325,689 px  (4.854%)\n",
      "  Class 2: 165,279,928 px  (28.324%)\n",
      "  Class 3: 84,708,720 px  (14.517%)\n",
      "  Class 4: 25,830,479 px  (4.427%)\n",
      "\n",
      "=== VAL CLASS FREQUENCIES ===\n",
      "Tiles: 782 | Total pixels: 204,996,608\n",
      "  Class 0: 101,261,018 px  (49.396%)\n",
      "  Class 1: 1,042,584 px  (0.509%)\n",
      "  Class 2: 61,640,157 px  (30.069%)\n",
      "  Class 3: 33,805,780 px  (16.491%)\n",
      "  Class 4: 7,247,069 px  (3.535%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vonkl\\AppData\\Local\\Temp\\ipykernel_25556\\1346023493.py:197: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:209.)\n",
      "  msk = torch.from_numpy(msk).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch fetched in 0.01 sec | img torch.Size([4, 1, 512, 512]) | msk torch.Size([4, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 557/557 [02:44<00:00,  3.39it/s, loss=1.4530, lr=2.06e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.4530  fast val_macroDice(ex-bg)~=0.3379 (50 batches)\n",
      "  ✅ saved best (FAST): 0.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 557/557 [02:03<00:00,  4.50it/s, loss=1.0944, lr=4.53e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=1.0944  fast val_macroDice(ex-bg)~=0.3848 (50 batches)\n",
      "  ✅ saved best (FAST): 0.3848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 557/557 [02:03<00:00,  4.51it/s, loss=0.9069, lr=8.32e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.9069  fast val_macroDice(ex-bg)~=0.4433 (50 batches)\n",
      "  ✅ saved best (FAST): 0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 557/557 [02:02<00:00,  4.53it/s, loss=0.7906, lr=1.30e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.7906  fast val_macroDice(ex-bg)~=0.4979 (50 batches)\n",
      "  ✅ saved best (FAST): 0.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 557/557 [02:02<00:00,  4.54it/s, loss=0.7518, lr=1.79e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.7518  fast val_macroDice(ex-bg)~=0.5401 (50 batches)\n",
      "  ✅ saved best (FAST): 0.5401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 557/557 [02:02<00:00,  4.54it/s, loss=0.6400, lr=2.26e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.6400  fast val_macroDice(ex-bg)~=0.5340 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 557/557 [02:03<00:00,  4.50it/s, loss=0.5410, lr=2.65e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.5410  fast val_macroDice(ex-bg)~=0.4753 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 557/557 [02:06<00:00,  4.42it/s, loss=0.4983, lr=2.90e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.4983  fast val_macroDice(ex-bg)~=0.5418 (50 batches)\n",
      "  ✅ saved best (FAST): 0.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 557/557 [02:03<00:00,  4.50it/s, loss=0.4729, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train_loss=0.4729  fast val_macroDice(ex-bg)~=0.5449 (50 batches)\n",
      "  ✅ saved best (FAST): 0.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 557/557 [02:01<00:00,  4.58it/s, loss=0.4158, lr=2.99e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train_loss=0.4158  FULL val_macroDice(ex-bg)=0.7011\n",
      "  ✅ saved best (FULL): 0.7011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 557/557 [02:02<00:00,  4.53it/s, loss=0.3772, lr=2.94e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: train_loss=0.3772  fast val_macroDice(ex-bg)~=0.5322 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 557/557 [02:00<00:00,  4.61it/s, loss=0.3555, lr=2.86e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: train_loss=0.3555  fast val_macroDice(ex-bg)~=0.5879 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 557/557 [02:01<00:00,  4.58it/s, loss=0.3308, lr=2.75e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: train_loss=0.3308  fast val_macroDice(ex-bg)~=0.5645 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 557/557 [02:01<00:00,  4.58it/s, loss=0.3287, lr=2.61e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: train_loss=0.3287  fast val_macroDice(ex-bg)~=0.6581 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 557/557 [02:02<00:00,  4.56it/s, loss=0.3090, lr=2.45e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: train_loss=0.3090  fast val_macroDice(ex-bg)~=0.6769 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 557/557 [02:01<00:00,  4.57it/s, loss=0.2865, lr=2.27e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: train_loss=0.2865  fast val_macroDice(ex-bg)~=0.6734 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 557/557 [02:02<00:00,  4.56it/s, loss=0.2920, lr=2.07e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: train_loss=0.2920  fast val_macroDice(ex-bg)~=0.6327 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 557/557 [02:01<00:00,  4.58it/s, loss=0.2850, lr=1.86e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: train_loss=0.2850  fast val_macroDice(ex-bg)~=0.6718 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 557/557 [02:02<00:00,  4.57it/s, loss=0.2596, lr=1.64e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: train_loss=0.2596  fast val_macroDice(ex-bg)~=0.7071 (50 batches)\n",
      "  ✅ saved best (FAST): 0.7071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 557/557 [02:03<00:00,  4.52it/s, loss=0.2641, lr=1.42e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: train_loss=0.2641  FULL val_macroDice(ex-bg)=0.6772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 557/557 [02:03<00:00,  4.52it/s, loss=0.2658, lr=1.20e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: train_loss=0.2658  fast val_macroDice(ex-bg)~=0.7152 (50 batches)\n",
      "  ✅ saved best (FAST): 0.7152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 557/557 [02:03<00:00,  4.52it/s, loss=0.2582, lr=9.83e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: train_loss=0.2582  fast val_macroDice(ex-bg)~=0.7106 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 557/557 [02:03<00:00,  4.52it/s, loss=0.2395, lr=7.81e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: train_loss=0.2395  fast val_macroDice(ex-bg)~=0.7178 (50 batches)\n",
      "  ✅ saved best (FAST): 0.7178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 557/557 [02:05<00:00,  4.44it/s, loss=0.2377, lr=5.94e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: train_loss=0.2377  fast val_macroDice(ex-bg)~=0.7869 (50 batches)\n",
      "  ✅ saved best (FAST): 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 557/557 [02:10<00:00,  4.26it/s, loss=0.2411, lr=4.27e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: train_loss=0.2411  fast val_macroDice(ex-bg)~=0.7746 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 557/557 [02:14<00:00,  4.16it/s, loss=0.2377, lr=2.84e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: train_loss=0.2377  fast val_macroDice(ex-bg)~=0.7703 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 557/557 [02:08<00:00,  4.33it/s, loss=0.2360, lr=1.67e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: train_loss=0.2360  fast val_macroDice(ex-bg)~=0.7912 (50 batches)\n",
      "  ✅ saved best (FAST): 0.7912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 557/557 [02:18<00:00,  4.03it/s, loss=0.2381, lr=8.00e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: train_loss=0.2381  fast val_macroDice(ex-bg)~=0.7849 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 557/557 [02:05<00:00,  4.45it/s, loss=0.2359, lr=2.41e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: train_loss=0.2359  fast val_macroDice(ex-bg)~=0.7799 (50 batches)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 557/557 [02:00<00:00,  4.61it/s, loss=0.2250, lr=7.32e-08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: train_loss=0.2250  FULL val_macroDice(ex-bg)=0.7978\n",
      "  ✅ saved best (FULL): 0.7978\n",
      "Best val dice: 0.7978042656478336 | based on FULL\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    raw_paths = find_raw_files(ORIGINAL_DATA_DIR)\n",
    "    if len(raw_paths) == 0:\n",
    "        raise RuntimeError(\n",
    "            f\"No raw files found in {ORIGINAL_DATA_DIR}. Expected raw_*.tif/.tiff (and matching label_*)\"\n",
    "        )\n",
    "\n",
    "    train_paths, val_paths = split_images(raw_paths, VAL_SPLIT, SEED)\n",
    "\n",
    "    print(\"=== IMAGE SPLIT ===\")\n",
    "    print(\"Train raw images:\", len(train_paths))\n",
    "    print(\"Val raw images:  \", len(val_paths))\n",
    "    print(\"Train files:\", [os.path.basename(p) for p in train_paths])\n",
    "    print(\"Val files:  \", [os.path.basename(p) for p in val_paths])\n",
    "\n",
    "   \n",
    "    if not processed_exists(PROCESSED_DIR):\n",
    "        print(\"\\n[cache miss] building tiled dataset...\")\n",
    "        cleanup_dir(PROCESSED_DIR)\n",
    "        tile_and_save(train_paths, PROCESSED_DIR, subset=\"train\")\n",
    "        tile_and_save(val_paths,   PROCESSED_DIR, subset=\"val\")\n",
    "        build_and_save_tile_weights(PROCESSED_DIR, \"train\", num_classes=NUM_CLASSES)\n",
    "    else:\n",
    "        print(\"\\n[cache hit] using existing tiles in:\", PROCESSED_DIR)\n",
    "\n",
    "    print(\"\\n=== TILE COUNTS ===\")\n",
    "    train_tiles = len(glob.glob(os.path.join(PROCESSED_DIR, \"train\", \"masks\", \"*.npy\")))\n",
    "    val_tiles   = len(glob.glob(os.path.join(PROCESSED_DIR, \"val\",   \"masks\", \"*.npy\")))\n",
    "    print(f\"Train tiles: {train_tiles}\")\n",
    "    print(f\"Val tiles:   {val_tiles}\")\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        counts, freqs, total, ntiles = class_frequencies_from_tiles(PROCESSED_DIR, split, num_classes=NUM_CLASSES)\n",
    "        print(f\"\\n=== {split.upper()} CLASS FREQUENCIES ===\")\n",
    "        print(f\"Tiles: {ntiles} | Total pixels: {total:,}\")\n",
    "        for k in range(NUM_CLASSES):\n",
    "            print(f\"  Class {k}: {counts[k]:,} px  ({freqs[k]*100:.3f}%)\")\n",
    "\n",
    " \n",
    "    train(\n",
    "        processed_dir=PROCESSED_DIR,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        accum_steps=ACCUM_STEPS,\n",
    "        lr=LR,\n",
    "        base_ch=BASE_CH,\n",
    "        use_amp=USE_AMP,\n",
    "        device=DEVICE,\n",
    "        num_workers=0 \n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "CLASS_COLORS = np.array([\n",
    "    [0,   0,   0],    \n",
    "    [255, 0,   0],    \n",
    "    [0,   255, 0],    \n",
    "    [0,   0,   255],  \n",
    "    [255, 255, 0],    \n",
    "], dtype=np.uint8)\n",
    "\n",
    "def colorize_mask(mask_2d):\n",
    "\n",
    "    mask_2d = mask_2d.astype(np.int64)\n",
    "    return CLASS_COLORS[np.clip(mask_2d, 0, len(CLASS_COLORS)-1)]\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_qualitative_batch(model, val_loader, device, out_dir, epoch, max_items=4):\n",
    "    \n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "\n",
    "    img, msk = next(iter(val_loader))\n",
    "    img = img.to(device, non_blocking=True)\n",
    "    msk = msk.to(device, non_blocking=True)\n",
    "\n",
    "    out0, _, _ = model(img)\n",
    "    probs = torch.softmax(out0, dim=1)          \n",
    "    pred = probs.argmax(dim=1)                  \n",
    "\n",
    "    B = min(img.shape[0], max_items)\n",
    "\n",
    "    for i in range(B):\n",
    "        raw = img[i,0].detach().cpu().numpy()\n",
    "        gt  = msk[i].detach().cpu().numpy()\n",
    "        pr  = pred[i].detach().cpu().numpy()\n",
    "\n",
    "        gt_rgb = colorize_mask(gt)\n",
    "        pr_rgb = colorize_mask(pr)\n",
    "\n",
    "        err = (pr != gt).astype(np.uint8) * 255\n",
    "\n",
    " \n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        ax = fig.add_subplot(gs[0,0]); ax.imshow(raw, cmap=\"gray\"); ax.set_title(\"Raw\"); ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(gs[0,1]); ax.imshow(gt_rgb); ax.set_title(\"GT mask\"); ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(gs[0,2]); ax.imshow(pr_rgb); ax.set_title(\"Pred mask\"); ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(gs[0,3]); ax.imshow(err, cmap=\"gray\"); ax.set_title(\"Error (pred!=gt)\"); ax.axis(\"off\")\n",
    "\n",
    "        for c in range(1, NUM_CLASSES):\n",
    "            ax = fig.add_subplot(gs[1, c-1])\n",
    "            hm = probs[i, c].detach().cpu().numpy()\n",
    "            ax.imshow(hm, vmin=0.0, vmax=1.0)\n",
    "            ax.set_title(f\"P(class {c})\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        fig.suptitle(f\"Epoch {epoch} | val sample {i}\", fontsize=12)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(out_dir, f\"epoch_{epoch:03d}_val_{i}.png\"), dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "def append_csv_row(csv_path, row_dict, header=None):\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=header or list(row_dict.keys()))\n",
    "        if not file_exists:\n",
    "            w.writeheader()\n",
    "        w.writerow(row_dict)\n",
    "\n",
    "def plot_training_curves(log_csv, out_path_prefix):\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(log_csv)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df[\"epoch\"], df[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.twinx()\n",
    "    plt.plot(df[\"epoch\"], df[\"lr\"], label=\"lr\")\n",
    "    plt.title(\"Train loss + LR\")\n",
    "    plt.savefig(out_path_prefix + \"_loss_lr.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df[\"epoch\"], df[\"val_dice\"], label=\"val_dice\")\n",
    "    plt.title(\"Val macroDice (ex-bg)\")\n",
    "    plt.savefig(out_path_prefix + \"_dice.png\", dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    processed_dir,\n",
    "    epochs=30,\n",
    "    batch_size=4,\n",
    "    accum_steps=4,\n",
    "    lr=3e-4,\n",
    "    base_ch=48,\n",
    "    use_amp=True,\n",
    "    device=\"cuda\",\n",
    "    num_workers=0,\n",
    "):\n",
    "   \n",
    "    DO_FULL_VAL_EVERY = 10\n",
    "    FAST_VAL_BATCHES  = 50\n",
    "    FORCE_FULL_AT     = 30\n",
    "\n",
    "    SAVE_VIS_EVERY    = 5   \n",
    "    MAX_VIS_ITEMS     = 4   \n",
    "\n",
    "    LOG_DIR = os.path.join(processed_dir, \"runs\", \"resattn_unet\")\n",
    "    VIS_DIR = os.path.join(LOG_DIR, \"viz\")\n",
    "    LOG_CSV = os.path.join(LOG_DIR, \"metrics.csv\")\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fast_val(model, val_loader, device, n_batches):\n",
    "        model.eval()\n",
    "        dices = []\n",
    "        for b, (img, msk) in enumerate(val_loader):\n",
    "            if b >= n_batches:\n",
    "                break\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            msk = msk.to(device, non_blocking=True)\n",
    "            out0, _, _ = model(img)\n",
    "            pred = out0.argmax(dim=1)\n",
    "            dices.append(macro_dice_ex_bg(pred, msk, n_classes=NUM_CLASSES))\n",
    "        return float(np.mean(dices)) if dices else 0.0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def full_val(model, val_loader, device):\n",
    "        model.eval()\n",
    "        dices = []\n",
    "        for img, msk in val_loader:\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            msk = msk.to(device, non_blocking=True)\n",
    "            out0, _, _ = model(img)\n",
    "            pred = out0.argmax(dim=1)\n",
    "            dices.append(macro_dice_ex_bg(pred, msk, n_classes=NUM_CLASSES))\n",
    "        return float(np.mean(dices)) if dices else 0.0\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    amp_on = (use_amp and str(device).startswith(\"cuda\"))\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=amp_on)\n",
    "\n",
    "    train_ds = TiledNPYDataset(processed_dir, \"train\")\n",
    "    val_ds   = TiledNPYDataset(processed_dir, \"val\")\n",
    "\n",
    "    class_w = compute_class_weights_from_mask_files(train_ds.msk_paths, NUM_CLASSES, device)\n",
    "\n",
    "    w_path = os.path.join(processed_dir, \"train\", \"tile_weights.npy\")\n",
    "    if not os.path.exists(w_path):\n",
    "        build_and_save_tile_weights(processed_dir, \"train\", num_classes=NUM_CLASSES)\n",
    "    tile_weights = np.load(w_path)\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=torch.DoubleTensor(tile_weights),\n",
    "        num_samples=len(tile_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, sampler=sampler,\n",
    "        num_workers=num_workers, pin_memory=str(device).startswith(\"cuda\")\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=str(device).startswith(\"cuda\")\n",
    "    )\n",
    "\n",
    "    smoke_test_loader(train_loader)\n",
    "\n",
    "    model = ResAttnUNetDS(n_classes=NUM_CLASSES, base=base_ch).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    steps_per_epoch = math.ceil(len(train_loader) / accum_steps)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt, max_lr=lr, epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "    )\n",
    "\n",
    "    criterion = ComboLoss(class_w, dice_w=0.7, ce_w=0.3)\n",
    "\n",
    "    best = -1.0\n",
    "    best_is_full = False\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "\n",
    "    \n",
    "    header = [\"epoch\", \"train_loss\", \"val_dice\", \"val_mode\", \"lr\"]\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {ep+1}/{epochs}\")\n",
    "        for i, (img, msk) in pbar:\n",
    "            img = img.to(device, non_blocking=True)\n",
    "            msk = msk.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=amp_on):\n",
    "                out0, out1, out2 = model(img)\n",
    "\n",
    "                m1 = F.interpolate(msk.unsqueeze(1).float(), scale_factor=0.5, mode=\"nearest\").squeeze(1).long()\n",
    "                m2 = F.interpolate(msk.unsqueeze(1).float(), scale_factor=0.25, mode=\"nearest\").squeeze(1).long()\n",
    "\n",
    "                loss0 = criterion(out0, msk)\n",
    "                loss1 = criterion(out1, m1)\n",
    "                loss2 = criterion(out2, m2)\n",
    "\n",
    "                loss = (loss0 + 0.5*loss1 + 0.25*loss2) / accum_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % accum_steps == 0:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                sched.step()\n",
    "\n",
    "            run_loss += loss.item() * accum_steps\n",
    "            pbar.set_postfix(loss=f\"{run_loss/(i+1):.4f}\", lr=f\"{sched.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        train_loss_ep = run_loss / max(1, len(train_loader))\n",
    "        cur_lr = float(sched.get_last_lr()[0])\n",
    "\n",
    "     \n",
    "        if (ep + 1) == FORCE_FULL_AT:\n",
    "            val_d = full_val(model, val_loader, device)\n",
    "            is_full = True\n",
    "            mode = \"FORCED_FULL\"\n",
    "            print(f\"Epoch {ep+1}: train_loss={train_loss_ep:.4f}  FORCED FULL val_macroDice(ex-bg)={val_d:.4f}\")\n",
    "        elif (ep + 1) % DO_FULL_VAL_EVERY == 0:\n",
    "            val_d = full_val(model, val_loader, device)\n",
    "            is_full = True\n",
    "            mode = \"FULL\"\n",
    "            print(f\"Epoch {ep+1}: train_loss={train_loss_ep:.4f}  FULL val_macroDice(ex-bg)={val_d:.4f}\")\n",
    "        else:\n",
    "            val_d = fast_val(model, val_loader, device, FAST_VAL_BATCHES)\n",
    "            is_full = False\n",
    "            mode = \"FAST\"\n",
    "            print(f\"Epoch {ep+1}: train_loss={train_loss_ep:.4f}  fast val_macroDice(ex-bg)~={val_d:.4f} ({FAST_VAL_BATCHES} batches)\")\n",
    "\n",
    "        append_csv_row(LOG_CSV, {\n",
    "            \"epoch\": ep+1,\n",
    "            \"train_loss\": train_loss_ep,\n",
    "            \"val_dice\": val_d,\n",
    "            \"val_mode\": mode,\n",
    "            \"lr\": cur_lr\n",
    "        }, header=header)\n",
    "\n",
    "\n",
    "        if val_d > best:\n",
    "            best = val_d\n",
    "            best_is_full = is_full\n",
    "            torch.save(model.state_dict(), \"best_resattn_unet_ds.pth\")\n",
    "            tag = \"FULL\" if is_full else \"FAST\"\n",
    "            print(f\"   saved best ({tag}): {best:.4f}\")\n",
    "\n",
    "        if (ep + 1) % SAVE_VIS_EVERY == 0 or (ep + 1) == 1 or (ep + 1) == FORCE_FULL_AT:\n",
    "            save_qualitative_batch(model, val_loader, device, VIS_DIR, epoch=ep+1, max_items=MAX_VIS_ITEMS)\n",
    "  \n",
    "            try:\n",
    "                plot_training_curves(LOG_CSV, os.path.join(LOG_DIR, \"curves\"))\n",
    "            except Exception as e:\n",
    "                print(\"Plotting failed (non-fatal):\", e)\n",
    "\n",
    "    print(\"Best val dice:\", best, \"| based on\", (\"FULL\" if best_is_full else \"FAST\"))\n",
    "    print(\"Logs saved to:\", LOG_CSV)\n",
    "    print(\"Viz saved to:\", VIS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def per_class_dice(pred, tgt, n_classes=NUM_CLASSES, eps=1e-6):\n",
    "  \n",
    "    dices = np.zeros(n_classes, dtype=np.float64)\n",
    "    for c in range(n_classes):\n",
    "        p = (pred == c)\n",
    "        t = (tgt == c)\n",
    "        inter = (p & t).sum()\n",
    "        denom = p.sum() + t.sum()\n",
    "        dices[c] = (2.0 * inter + eps) / (denom + eps)\n",
    "    return dices\n",
    "\n",
    "@torch.no_grad()\n",
    "def confusion_matrix_fast(pred, tgt, n_classes=NUM_CLASSES):\n",
    "  \n",
    "    pred = pred.reshape(-1)\n",
    "    tgt  = tgt.reshape(-1)\n",
    "    k = (tgt >= 0) & (tgt < n_classes)\n",
    "    idx = n_classes * tgt[k] + pred[k]\n",
    "    cm = np.bincount(idx, minlength=n_classes*n_classes).reshape(n_classes, n_classes)\n",
    "    return cm\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_full_val(model, val_loader, device, n_classes=NUM_CLASSES):\n",
    "    model.eval()\n",
    "    dice_list = []\n",
    "    cm_all = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
    "\n",
    "    for img, msk in tqdm(val_loader, desc=\"FULL EVAL\", leave=False):\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        msk = msk.to(device, non_blocking=True)\n",
    "\n",
    "        out0, _, _ = model(img)                 \n",
    "        pred = out0.argmax(dim=1)              \n",
    "\n",
    "        pred_np = pred.detach().cpu().numpy().astype(np.int64)\n",
    "        msk_np  = msk.detach().cpu().numpy().astype(np.int64)\n",
    "\n",
    "        for b in range(pred_np.shape[0]):\n",
    "            dices = per_class_dice(pred_np[b], msk_np[b], n_classes=n_classes)\n",
    "            dice_list.append(dices)\n",
    "            cm_all += confusion_matrix_fast(pred_np[b], msk_np[b], n_classes=n_classes)\n",
    "\n",
    "    dice_mean = np.mean(np.stack(dice_list, axis=0), axis=0) if dice_list else np.zeros(n_classes)\n",
    "    return dice_mean, cm_all\n",
    "\n",
    "def save_confusion_heatmap(cm, out_path, title=\"Confusion Matrix\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Pred\")\n",
    "    plt.ylabel(\"GT\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_predictions_gallery(model, val_ds, device, out_dir, k=12, seed=0):\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idxs = rng.choice(len(val_ds), size=min(k, len(val_ds)), replace=False)\n",
    "\n",
    "    model.eval()\n",
    "    for j, idx in enumerate(idxs):\n",
    "        img, msk = val_ds[idx]\n",
    "        img_b = img.unsqueeze(0).to(device)\n",
    "        msk_b = msk.unsqueeze(0).to(device)\n",
    "\n",
    "        out0, _, _ = model(img_b)\n",
    "        probs = torch.softmax(out0, dim=1)[0]         \n",
    "        pred  = probs.argmax(dim=0)                \n",
    "\n",
    "        raw = img[0].numpy()\n",
    "        gt  = msk.numpy().astype(np.int64)\n",
    "        pr  = pred.detach().cpu().numpy().astype(np.int64)\n",
    "\n",
    "        gt_rgb = colorize_mask(gt)\n",
    "        pr_rgb = colorize_mask(pr)\n",
    "        err = (pr != gt).astype(np.uint8) * 255\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        gs = fig.add_gridspec(2, 4)\n",
    "\n",
    "        ax = fig.add_subplot(gs[0,0]); ax.imshow(raw, cmap=\"gray\"); ax.set_title(\"Raw\"); ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(gs[0,1]); ax.imshow(gt_rgb); ax.set_title(\"GT mask\"); ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(gs[0,2]); ax.imshow(pr_rgb); ax.set_title(\"Pred mask\"); ax.axis(\"off\")\n",
    "        ax = fig.add_subplot(gs[0,3]); ax.imshow(err, cmap=\"gray\"); ax.set_title(\"Error\"); ax.axis(\"off\")\n",
    "\n",
    "        for c in range(1, NUM_CLASSES):\n",
    "            ax = fig.add_subplot(gs[1, c-1])\n",
    "            hm = probs[c].detach().cpu().numpy()\n",
    "            ax.imshow(hm, vmin=0.0, vmax=1.0)\n",
    "            ax.set_title(f\"P(class {c})\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        fig.suptitle(f\"val tile idx={idx}\", fontsize=12)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(out_dir, f\"val_pred_{j:02d}_idx{idx}.png\"), dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "def evaluate_and_visualize(\n",
    "    processed_dir=PROCESSED_DIR,\n",
    "    ckpt_path=\"best_resattn_unet_ds.pth\",\n",
    "    base_ch=BASE_CH,\n",
    "    batch_size=4,\n",
    "    device=DEVICE,\n",
    "    num_workers=0,\n",
    "    out_dir=None,\n",
    "    k_examples=12\n",
    "):\n",
    "    if out_dir is None:\n",
    "        out_dir = os.path.join(processed_dir, \"eval_report\")\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    val_ds = TiledNPYDataset(processed_dir, \"val\")\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=str(device).startswith(\"cuda\"))\n",
    "\n",
    "    model = ResAttnUNetDS(n_classes=NUM_CLASSES, base=base_ch).to(device)\n",
    "    sd = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(sd)\n",
    "\n",
    "\n",
    "    dice_mean, cm = evaluate_full_val(model, val_loader, device, n_classes=NUM_CLASSES)\n",
    "\n",
    "    print(\"\\n=== FULL VAL REPORT (per-class Dice) ===\")\n",
    "    for c in range(NUM_CLASSES):\n",
    "        print(f\"Class {c}: Dice = {dice_mean[c]:.4f}\")\n",
    "    macro_ex_bg = float(np.mean(dice_mean[1:])) if NUM_CLASSES > 1 else float(dice_mean[0])\n",
    "    print(f\"\\nMacro Dice (exclude bg classes 1..{NUM_CLASSES-1}): {macro_ex_bg:.4f}\")\n",
    "\n",
    "\n",
    "    save_confusion_heatmap(cm, os.path.join(out_dir, \"confusion_matrix.png\"),\n",
    "                           title=\"Confusion Matrix (rows=GT, cols=Pred)\")\n",
    "\n",
    "\n",
    "    save_predictions_gallery(model, val_ds, device, os.path.join(out_dir, \"examples\"),\n",
    "                             k=k_examples, seed=SEED)\n",
    "\n",
    "    print(\"\\nSaved report to:\", out_dir)\n",
    "    print(\" - confusion_matrix.png\")\n",
    "    print(\" - examples/val_pred_*.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be54349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FULL VAL REPORT (per-class Dice) ===\n",
      "Class 0: Dice = 0.8436\n",
      "Class 1: Dice = 0.8705\n",
      "Class 2: Dice = 0.8867\n",
      "Class 3: Dice = 0.7751\n",
      "Class 4: Dice = 0.7953\n",
      "\n",
      "Macro Dice (exclude bg classes 1..4): 0.8319\n",
      "\n",
      "Saved report to: project/processed_tiles\\eval_report\n",
      " - confusion_matrix.png\n",
      " - examples/val_pred_*.png\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    evaluate_and_visualize(\n",
    "        processed_dir=PROCESSED_DIR,\n",
    "        ckpt_path=\"best_resattn_unet_ds.pth\",\n",
    "        base_ch=BASE_CH,\n",
    "        batch_size=4,\n",
    "        device=DEVICE,\n",
    "        num_workers=0,\n",
    "        k_examples=12\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
